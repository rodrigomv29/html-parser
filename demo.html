<!DOCTYPE html>
<html class="client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-zebra-design-disabled vector-feature-custom-font-size-clientpref-disabled vector-feature-client-preferences-disabled vector-feature-typography-survey-disabled vector-toc-available" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>Linear discriminant analysis - Wikipedia</title>
<script>(function(){var className="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-zebra-design-disabled vector-feature-custom-font-size-clientpref-disabled vector-feature-client-preferences-disabled vector-feature-typography-survey-disabled vector-toc-available";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\w+$|[^\w-]+/g,'')+'-clientpref-\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],
"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"1eab8681-e8e8-4fd3-9da4-efadfc8a2db6","wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Linear_discriminant_analysis","wgTitle":"Linear discriminant analysis","wgCurRevisionId":1170909811,"wgRevisionId":1170909811,"wgArticleId":1470657,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Articles with short description","Short description is different from Wikidata","Wikipedia articles needing clarification from April 2019","Wikipedia articles needing clarification from April 2012","Wikipedia articles needing clarification from May 2021","CS1 maint: date and year","Articles with J9U identifiers","Articles with LCCN identifiers","Classification algorithms","Market research","Market segmentation",
"Statistical classification"],"wgPageViewLanguage":"en","wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Linear_discriminant_analysis","wgRelevantArticleId":1470657,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgNoticeProject":"wikipedia","wgFlaggedRevsParams":{"tags":{"status":{"levels":1}}},"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":10,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"watchlist":true,"tagline":false,"nearby":true},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":50000,"wgULSCurrentAutonym":"English","wgCentralAuthMobileDomain":false,"wgEditSubmitButtonLabelPublish":true,"wgULSPosition":"interlanguage","wgULSisCompactLinksEnabled":true,"wgULSisLanguageSelectorEmpty":false,"wgWikibaseItemId":"Q1228929",
"wgCheckUserClientHintsHeadersJsApi":["architecture","bitness","brands","fullVersionList","mobile","model","platform","platformVersion"],"GEHomepageSuggestedEditsEnableTopics":true,"wgGETopicsMatchModeEnabled":false,"wgGEStructuredTaskRejectionReasonTextInputEnabled":false,"wgGELevelingUpEnabledForUser":false};RLSTATE={"skins.vector.user.styles":"ready","ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","skins.vector.user":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","codex-search-styles":"ready","skins.vector.styles":"ready","skins.vector.icons":"ready","jquery.makeCollapsible.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","mediawiki.page.media","ext.scribunto.logs","site","mediawiki.page.ready",
"jquery.makeCollapsible","mediawiki.toc","skins.vector.js","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.urlShortener.toolbar","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.echo.centralauth","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.cx.uls.quick.actions","wikibase.client.vector-2022","ext.checkUser.clientHints","ext.growthExperiments.SuggestedEditSession"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return["user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
}];});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=codex-search-styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cskins.vector.icons%2Cstyles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector-2022">
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector-2022"></script>
<meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector-2022">
<meta name="generator" content="MediaWiki 1.41.0-wmf.29">
<meta name="referrer" content="origin">
<meta name="referrer" content="origin-when-cross-origin">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta name="viewport" content="width=1000">
<meta property="og:title" content="Linear discriminant analysis - Wikipedia">
<meta property="og:type" content="website">
<link rel="preconnect" href="//upload.wikimedia.org">
<link rel="alternate" media="only screen and (max-width: 720px)" href="//en.m.wikipedia.org/wiki/Linear_discriminant_analysis">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit">
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png">
<link rel="icon" href="/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd">
<link rel="canonical" href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom">
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<link rel="dns-prefetch" href="//login.wikimedia.org">
</head>
<body class="skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Linear_discriminant_analysis rootpage-Linear_discriminant_analysis skin-vector-2022 action-view"><a class="mw-jump-link" href="#bodyContent">Jump to content</a>
<div class="vector-header-container">
	<header class="vector-header mw-header">
		<div class="vector-header-start">
			<nav class="vector-main-menu-landmark" aria-label="Site" role="navigation">
				
<div id="vector-main-menu-dropdown" class="vector-dropdown vector-main-menu-dropdown vector-button-flush-left vector-button-flush-right"  >
	<input type="checkbox" id="vector-main-menu-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-main-menu-dropdown" class="vector-dropdown-checkbox "  aria-label="Main menu"  >
	<label id="vector-main-menu-dropdown-label" for="vector-main-menu-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-menu mw-ui-icon-wikimedia-menu"></span>

<span class="vector-dropdown-label-text">Main menu</span>
	</label>
	<div class="vector-dropdown-content">


				<div id="vector-main-menu-unpinned-container" class="vector-unpinned-container">
		
<div id="vector-main-menu" class="vector-main-menu vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-main-menu-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="main-menu-pinned"
	data-pinnable-element-id="vector-main-menu"
	data-pinned-container-id="vector-main-menu-pinned-container"
	data-unpinned-container-id="vector-main-menu-unpinned-container"
>
	<div class="vector-pinnable-header-label">Main menu</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-main-menu.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-main-menu.unpin">hide</button>
</div>

	
<div id="p-navigation" class="vector-menu mw-portlet mw-portlet-navigation"  >
	<div class="vector-menu-heading">
		Navigation
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-mainpage-description" class="mw-list-item"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"><span>Main page</span></a></li><li id="n-contents" class="mw-list-item"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia"><span>Contents</span></a></li><li id="n-currentevents" class="mw-list-item"><a href="/wiki/Portal:Current_events" title="Articles related to current events"><span>Current events</span></a></li><li id="n-randompage" class="mw-list-item"><a href="/wiki/Special:Random" title="Visit a randomly selected article [x]" accesskey="x"><span>Random article</span></a></li><li id="n-aboutsite" class="mw-list-item"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works"><span>About Wikipedia</span></a></li><li id="n-contactpage" class="mw-list-item"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia"><span>Contact us</span></a></li><li id="n-sitesupport" class="mw-list-item"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation"><span>Donate</span></a></li>
		</ul>
		
	</div>
</div>

	
	
<div id="p-interaction" class="vector-menu mw-portlet mw-portlet-interaction"  >
	<div class="vector-menu-heading">
		Contribute
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-help" class="mw-list-item"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia"><span>Help</span></a></li><li id="n-introduction" class="mw-list-item"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia"><span>Learn to edit</span></a></li><li id="n-portal" class="mw-list-item"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors"><span>Community portal</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r"><span>Recent changes</span></a></li><li id="n-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_upload_wizard" title="Add images or other media for use on Wikipedia"><span>Upload file</span></a></li>
		</ul>
		
	</div>
</div>

	
<div class="vector-main-menu-action vector-main-menu-action-lang-alert">
	<div class="vector-main-menu-action-item">
		<div class="vector-main-menu-action-heading vector-menu-heading">Languages</div>
		<div class="vector-main-menu-action-content vector-menu-content">
			<div class="mw-message-box cdx-message cdx-message--block mw-message-box-notice cdx-message--notice vector-language-sidebar-alert"><span class="cdx-message__icon"></span><div class="cdx-message__content">Language links are at the top of the page across from the title.</div></div>
		</div>
	</div>
</div>

</div>

				</div>

	</div>
</div>

		</nav>
			
<a href="/wiki/Main_Page" class="mw-logo">
	<img class="mw-logo-icon" src="/static/images/icons/wikipedia.png" alt="" aria-hidden="true" height="50" width="50">
	<span class="mw-logo-container">
		<img class="mw-logo-wordmark" alt="Wikipedia" src="/static/images/mobile/copyright/wikipedia-wordmark-en.svg" style="width: 7.5em; height: 1.125em;">
		<img class="mw-logo-tagline" alt="The Free Encyclopedia" src="/static/images/mobile/copyright/wikipedia-tagline-en.svg" width="117" height="13" style="width: 7.3125em; height: 0.8125em;">
	</span>
</a>

		</div>
		<div class="vector-header-end">
			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-collapses vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<a href="/wiki/Special:Search" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only search-toggle" id="" title="Search Wikipedia [f]" accesskey="f"><span class="vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search"></span>

<span>Search</span>
	</a>
	<div class="vector-typeahead-search-container">
		<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail cdx-typeahead-search--auto-expand-width">
			<form action="/w/index.php" id="searchform" class="cdx-search-input cdx-search-input--has-end-button">
				<div id="simpleSearch" class="cdx-search-input__input-wrapper"  data-search-loc="header-moved">
					<div class="cdx-text-input cdx-text-input--has-start-icon">
						<input
							class="cdx-text-input__input"
							 type="search" name="search" placeholder="Search Wikipedia" aria-label="Search Wikipedia" autocapitalize="sentences" title="Search Wikipedia [f]" accesskey="f" id="searchInput"
							>
						<span class="cdx-text-input__icon cdx-text-input__start-icon"></span>
					</div>
					<input type="hidden" name="title" value="Special:Search">
				</div>
				<button class="cdx-button cdx-search-input__end-button">Search</button>
			</form>
		</div>
	</div>
</div>

			<nav class="vector-user-links" aria-label="Personal tools" role="navigation" >
	
<div id="p-vector-user-menu-overflow" class="vector-menu mw-portlet mw-portlet-vector-user-menu-overflow"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-createaccount-2" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Linear+discriminant+analysis" title="You are encouraged to create an account and log in; however, it is not mandatory"><span>Create account</span></a></li><li id="pt-login-2" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Linear+discriminant+analysis" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o"><span>Log in</span></a></li>
		</ul>
		
	</div>
</div>

	
<div id="vector-user-links-dropdown" class="vector-dropdown vector-user-menu vector-button-flush-right vector-user-menu-logged-out"  title="Log in and more options" >
	<input type="checkbox" id="vector-user-links-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-user-links-dropdown" class="vector-dropdown-checkbox "  aria-label="Personal tools"  >
	<label id="vector-user-links-dropdown-label" for="vector-user-links-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-ellipsis mw-ui-icon-wikimedia-ellipsis"></span>

<span class="vector-dropdown-label-text">Personal tools</span>
	</label>
	<div class="vector-dropdown-content">


		
<div id="p-personal" class="vector-menu mw-portlet mw-portlet-personal user-links-collapsible-item"  title="User menu" >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-createaccount" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Linear+discriminant+analysis" title="You are encouraged to create an account and log in; however, it is not mandatory"><span class="vector-icon mw-ui-icon-userAdd mw-ui-icon-wikimedia-userAdd"></span> <span>Create account</span></a></li><li id="pt-login" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Linear+discriminant+analysis" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o"><span class="vector-icon mw-ui-icon-logIn mw-ui-icon-wikimedia-logIn"></span> <span>Log in</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-user-menu-anon-editor" class="vector-menu mw-portlet mw-portlet-user-menu-anon-editor"  >
	<div class="vector-menu-heading">
		Pages for logged out editors <a href="/wiki/Help:Introduction" aria-label="Learn more about editing"><span>learn more</span></a>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-anoncontribs" class="mw-list-item"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y"><span>Contributions</span></a></li><li id="pt-anontalk" class="mw-list-item"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

	
	</div>
</div>

</nav>

		</div>
	</header>
</div>
<div class="mw-page-container">
	<div class="mw-page-container-inner">
		<div class="vector-main-menu-container">
			<div id="mw-navigation">
				<nav id="mw-panel" class="vector-main-menu-landmark" aria-label="Site" role="navigation">
					<div id="vector-main-menu-pinned-container" class="vector-pinned-container">
				
					</div>
		</nav>
			</div>
		</div>
		<div class="vector-sitenotice-container">
			<div id="siteNotice"><!-- CentralNotice --></div>
		</div>
		<input type="checkbox" id="vector-toc-collapsed-checkbox" class="vector-menu-checkbox">
		<nav id="mw-panel-toc" role="navigation" aria-label="Contents" data-event-name="ui.sidebar-toc" class="mw-table-of-contents-container vector-toc-landmark vector-sticky-pinned-container">
			<div id="vector-toc-pinned-container" class="vector-pinned-container">
					<div id="vector-toc" class="vector-toc vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned"
	data-feature-name="toc-pinned"
	data-pinnable-element-id="vector-toc"
	
	
>
	<h2 class="vector-pinnable-header-label">Contents</h2>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-toc.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button>
</div>


	<ul class="vector-toc-contents" id="mw-panel-toc-list">
		<li id="toc-mw-content-text"
			class="vector-toc-list-item vector-toc-level-1">
			<a href="#" class="vector-toc-link">
				<div class="vector-toc-text">(Top)</div>
			</a>
		</li>
		<li id="toc-History"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#History">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">1</span>History</div>
		</a>
		
		<ul id="toc-History-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-LDA_for_two_classes"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#LDA_for_two_classes">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">2</span>LDA for two classes</div>
		</a>
		
		<ul id="toc-LDA_for_two_classes-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Assumptions"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Assumptions">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">3</span>Assumptions</div>
		</a>
		
		<ul id="toc-Assumptions-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Discriminant_functions"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Discriminant_functions">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">4</span>Discriminant functions</div>
		</a>
		
		<ul id="toc-Discriminant_functions-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Discrimination_rules"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Discrimination_rules">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">5</span>Discrimination rules</div>
		</a>
		
		<ul id="toc-Discrimination_rules-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Eigenvalues"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Eigenvalues">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">6</span>Eigenvalues</div>
		</a>
		
		<ul id="toc-Eigenvalues-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Effect_size"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Effect_size">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">7</span>Effect size</div>
		</a>
		
		<ul id="toc-Effect_size-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Canonical_discriminant_analysis_for_k_classes"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Canonical_discriminant_analysis_for_k_classes">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">8</span>Canonical discriminant analysis for <i>k</i> classes</div>
		</a>
		
		<ul id="toc-Canonical_discriminant_analysis_for_k_classes-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Fisher&#039;s_linear_discriminant"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Fisher&#039;s_linear_discriminant">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">9</span>Fisher's linear discriminant</div>
		</a>
		
		<ul id="toc-Fisher&#039;s_linear_discriminant-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Multiclass_LDA"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Multiclass_LDA">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">10</span>Multiclass LDA</div>
		</a>
		
		<ul id="toc-Multiclass_LDA-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Incremental_LDA"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Incremental_LDA">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">11</span>Incremental LDA</div>
		</a>
		
		<ul id="toc-Incremental_LDA-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Practical_use"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Practical_use">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">12</span>Practical use</div>
		</a>
		
		<ul id="toc-Practical_use-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Applications"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Applications">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">13</span>Applications</div>
		</a>
		
			<button aria-controls="toc-Applications-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Applications subsection</span>
			</button>
		
		<ul id="toc-Applications-sublist" class="vector-toc-list">
			<li id="toc-Bankruptcy_prediction"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Bankruptcy_prediction">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">13.1</span>Bankruptcy prediction</div>
			</a>
			
			<ul id="toc-Bankruptcy_prediction-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Face_recognition"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Face_recognition">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">13.2</span>Face recognition</div>
			</a>
			
			<ul id="toc-Face_recognition-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Marketing"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Marketing">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">13.3</span>Marketing</div>
			</a>
			
			<ul id="toc-Marketing-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Biomedical_studies"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Biomedical_studies">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">13.4</span>Biomedical studies</div>
			</a>
			
			<ul id="toc-Biomedical_studies-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Earth_science"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Earth_science">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">13.5</span>Earth science</div>
			</a>
			
			<ul id="toc-Earth_science-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Comparison_to_logistic_regression"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Comparison_to_logistic_regression">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">14</span>Comparison to logistic regression</div>
		</a>
		
		<ul id="toc-Comparison_to_logistic_regression-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Linear_discriminant_in_high_dimension"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Linear_discriminant_in_high_dimension">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">15</span>Linear discriminant in high dimension</div>
		</a>
		
		<ul id="toc-Linear_discriminant_in_high_dimension-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-See_also"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#See_also">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">16</span>See also</div>
		</a>
		
		<ul id="toc-See_also-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-References"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#References">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">17</span>References</div>
		</a>
		
		<ul id="toc-References-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Further_reading"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Further_reading">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">18</span>Further reading</div>
		</a>
		
		<ul id="toc-Further_reading-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-External_links"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#External_links">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">19</span>External links</div>
		</a>
		
		<ul id="toc-External_links-sublist" class="vector-toc-list">
		</ul>
	</li>
</ul>
</div>

			</div>
		</nav>
		<div class="mw-content-container">
			<main id="content" class="mw-body" role="main">
				<header class="mw-body-header vector-page-titlebar">
					<label
						id="vector-toc-collapsed-button"
						class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet vector-button-flush-left cdx-button--icon-only"
						for="vector-toc-collapsed-checkbox"
						role="button"
						aria-controls="vector-toc"
						tabindex="0"
						title="Table of Contents">
						<span class="vector-icon mw-ui-icon-wikimedia-listBullet"></span>
						<span>Toggle the table of contents</span>
					</label>
					<nav role="navigation" aria-label="Contents" class="vector-toc-landmark">
						
<div id="vector-page-titlebar-toc" class="vector-dropdown vector-page-titlebar-toc vector-button-flush-left"  >
	<input type="checkbox" id="vector-page-titlebar-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-titlebar-toc" class="vector-dropdown-checkbox "  aria-label="Toggle the table of contents"  >
	<label id="vector-page-titlebar-toc-label" for="vector-page-titlebar-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
	</label>
	<div class="vector-dropdown-content">


							<div id="vector-page-titlebar-toc-unpinned-container" class="vector-unpinned-container">
			</div>
		
	</div>
</div>

					</nav>
					<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">Linear discriminant analysis</span></h1>
							
<div id="p-lang-btn" class="vector-dropdown mw-portlet mw-portlet-lang"  >
	<input type="checkbox" id="p-lang-btn-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-lang-btn" class="vector-dropdown-checkbox mw-interlanguage-selector" aria-label="Go to an article in another language. Available in 18 languages"   >
	<label id="p-lang-btn-label" for="p-lang-btn-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-18" aria-hidden="true"  ><span class="vector-icon mw-ui-icon-language-progressive mw-ui-icon-wikimedia-language-progressive"></span>

<span class="vector-dropdown-label-text">18 languages</span>
	</label>
	<div class="vector-dropdown-content">

		<div class="vector-menu-content">
			
			<ul class="vector-menu-content-list">
				
				<li class="interlanguage-link interwiki-ar mw-list-item"><a href="https://ar.wikipedia.org/wiki/%D8%AA%D8%AD%D9%84%D9%8A%D9%84_%D8%A7%D9%84%D8%AA%D9%85%D9%8A%D9%8A%D8%B2_%D8%A7%D9%84%D8%AE%D8%B7%D9%8A" title="تحليل التمييز الخطي – Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target"><span>العربية</span></a></li><li class="interlanguage-link interwiki-be mw-list-item"><a href="https://be.wikipedia.org/wiki/%D0%9B%D1%96%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B_%D0%B4%D1%8B%D1%81%D0%BA%D1%80%D1%8B%D0%BC%D1%96%D0%BD%D0%B0%D0%BD%D1%82%D0%BD%D1%8B_%D0%B0%D0%BD%D0%B0%D0%BB%D1%96%D0%B7" title="Лінейны дыскрымінантны аналіз – Belarusian" lang="be" hreflang="be" class="interlanguage-link-target"><span>Беларуская</span></a></li><li class="interlanguage-link interwiki-ca mw-list-item"><a href="https://ca.wikipedia.org/wiki/An%C3%A0lisi_discriminant_lineal" title="Anàlisi discriminant lineal – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target"><span>Català</span></a></li><li class="interlanguage-link interwiki-es mw-list-item"><a href="https://es.wikipedia.org/wiki/An%C3%A1lisis_discriminante_lineal" title="Análisis discriminante lineal – Spanish" lang="es" hreflang="es" class="interlanguage-link-target"><span>Español</span></a></li><li class="interlanguage-link interwiki-eo mw-list-item"><a href="https://eo.wikipedia.org/wiki/Lineara_diskriminanta_analitiko" title="Lineara diskriminanta analitiko – Esperanto" lang="eo" hreflang="eo" class="interlanguage-link-target"><span>Esperanto</span></a></li><li class="interlanguage-link interwiki-fa mw-list-item"><a href="https://fa.wikipedia.org/wiki/%D8%A2%D9%86%D8%A7%D9%84%DB%8C%D8%B2_%D8%A7%D9%81%D8%AA%D8%B1%D8%A7%D9%82%DB%8C_%D8%AE%D8%B7%DB%8C" title="آنالیز افتراقی خطی – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target"><span>فارسی</span></a></li><li class="interlanguage-link interwiki-fr mw-list-item"><a href="https://fr.wikipedia.org/wiki/Analyse_discriminante_lin%C3%A9aire" title="Analyse discriminante linéaire – French" lang="fr" hreflang="fr" class="interlanguage-link-target"><span>Français</span></a></li><li class="interlanguage-link interwiki-hr mw-list-item"><a href="https://hr.wikipedia.org/wiki/Linearna_analiza_razli%C4%8Ditih" title="Linearna analiza različitih – Croatian" lang="hr" hreflang="hr" class="interlanguage-link-target"><span>Hrvatski</span></a></li><li class="interlanguage-link interwiki-id mw-list-item"><a href="https://id.wikipedia.org/wiki/Analisis_diskriminan_linear" title="Analisis diskriminan linear – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target"><span>Bahasa Indonesia</span></a></li><li class="interlanguage-link interwiki-it mw-list-item"><a href="https://it.wikipedia.org/wiki/Analisi_discriminante_lineare" title="Analisi discriminante lineare – Italian" lang="it" hreflang="it" class="interlanguage-link-target"><span>Italiano</span></a></li><li class="interlanguage-link interwiki-hu mw-list-item"><a href="https://hu.wikipedia.org/wiki/Line%C3%A1ris_diszkriminanciaanal%C3%ADzis" title="Lineáris diszkriminanciaanalízis – Hungarian" lang="hu" hreflang="hu" class="interlanguage-link-target"><span>Magyar</span></a></li><li class="interlanguage-link interwiki-pl mw-list-item"><a href="https://pl.wikipedia.org/wiki/Liniowa_analiza_dyskryminacyjna" title="Liniowa analiza dyskryminacyjna – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target"><span>Polski</span></a></li><li class="interlanguage-link interwiki-ru mw-list-item"><a href="https://ru.wikipedia.org/wiki/%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D0%B4%D0%B8%D1%81%D0%BA%D1%80%D0%B8%D0%BC%D0%B8%D0%BD%D0%B0%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7" title="Линейный дискриминантный анализ – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target"><span>Русский</span></a></li><li class="interlanguage-link interwiki-su mw-list-item"><a href="https://su.wikipedia.org/wiki/Fisher%27s_linear_discriminator" title="Fisher&#039;s linear discriminator – Sundanese" lang="su" hreflang="su" class="interlanguage-link-target"><span>Sunda</span></a></li><li class="interlanguage-link interwiki-tr mw-list-item"><a href="https://tr.wikipedia.org/wiki/Do%C4%9Frusal_ay%C4%B1rma_analizi" title="Doğrusal ayırma analizi – Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target"><span>Türkçe</span></a></li><li class="interlanguage-link interwiki-uk mw-list-item"><a href="https://uk.wikipedia.org/wiki/%D0%9B%D1%96%D0%BD%D1%96%D0%B9%D0%BD%D0%B8%D0%B9_%D1%80%D0%BE%D0%B7%D0%B4%D1%96%D0%BB%D1%8E%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D1%96%D0%B7" title="Лінійний розділювальний аналіз – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target"><span>Українська</span></a></li><li class="interlanguage-link interwiki-zh-yue mw-list-item"><a href="https://zh-yue.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E5%88%A4%E5%88%A5%E5%88%86%E6%9E%90" title="線性判別分析 – Cantonese" lang="yue" hreflang="yue" class="interlanguage-link-target"><span>粵語</span></a></li><li class="interlanguage-link interwiki-zh mw-list-item"><a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E5%88%A4%E5%88%A5%E5%88%86%E6%9E%90" title="線性判別分析 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target"><span>中文</span></a></li>
			</ul>
			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1228929#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
		</div>

	</div>
</div>
</header>
				<div class="vector-page-toolbar">
					<div class="vector-page-toolbar-container">
						<div id="left-navigation">
							<nav aria-label="Namespaces">
								
<div id="p-associated-pages" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-nstab-main" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/Linear_discriminant_analysis" title="View the content page [c]" accesskey="c"><span>Article</span></a></li><li id="ca-talk" class="vector-tab-noicon mw-list-item"><a href="/wiki/Talk:Linear_discriminant_analysis" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

								
<div id="p-variants" class="vector-dropdown emptyPortlet"  >
	<input type="checkbox" id="p-variants-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-variants" class="vector-dropdown-checkbox " aria-label="Change language variant"   >
	<label id="p-variants-label" for="p-variants-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">English</span>
	</label>
	<div class="vector-dropdown-content">


					
<div id="p-variants" class="vector-menu mw-portlet mw-portlet-variants emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

				
	</div>
</div>

							</nav>
						</div>
						<div id="right-navigation" class="vector-collapsible">
							<nav aria-label="Views">
								
<div id="p-views" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-views"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-view" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/Linear_discriminant_analysis"><span>Read</span></a></li><li id="ca-edit" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-history" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=history" title="Past revisions of this page [h]" accesskey="h"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

							</nav>
				
							<nav class="vector-page-tools-landmark" aria-label="Page tools">
								
<div id="vector-page-tools-dropdown" class="vector-dropdown vector-page-tools-dropdown"  >
	<input type="checkbox" id="vector-page-tools-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-tools-dropdown" class="vector-dropdown-checkbox "  aria-label="Tools"  >
	<label id="vector-page-tools-dropdown-label" for="vector-page-tools-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">Tools</span>
	</label>
	<div class="vector-dropdown-content">


									<div id="vector-page-tools-unpinned-container" class="vector-unpinned-container">
						
<div id="vector-page-tools" class="vector-page-tools vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-page-tools-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="page-tools-pinned"
	data-pinnable-element-id="vector-page-tools"
	data-pinned-container-id="vector-page-tools-pinned-container"
	data-unpinned-container-id="vector-page-tools-unpinned-container"
>
	<div class="vector-pinnable-header-label">Tools</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-page-tools.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-page-tools.unpin">hide</button>
</div>

	
<div id="p-cactions" class="vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-has-collapsible-items"  title="More options" >
	<div class="vector-menu-heading">
		Actions
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-more-view" class="selected vector-more-collapsible-item mw-list-item"><a href="/wiki/Linear_discriminant_analysis"><span>Read</span></a></li><li id="ca-more-edit" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-more-history" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=history"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-tb" class="vector-menu mw-portlet mw-portlet-tb"  >
	<div class="vector-menu-heading">
		General
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-whatlinkshere" class="mw-list-item"><a href="/wiki/Special:WhatLinksHere/Linear_discriminant_analysis" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="/wiki/Special:RecentChangesLinked/Linear_discriminant_analysis" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k"><span>Related changes</span></a></li><li id="t-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u"><span>Upload file</span></a></li><li id="t-specialpages" class="mw-list-item"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q"><span>Special pages</span></a></li><li id="t-permalink" class="mw-list-item"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;oldid=1170909811" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=info" title="More information about this page"><span>Page information</span></a></li><li id="t-cite" class="mw-list-item"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Linear_discriminant_analysis&amp;id=1170909811&amp;wpFormIdentifier=titleform" title="Information on how to cite this page"><span>Cite this page</span></a></li><li id="t-urlshortener" class="mw-list-item"><a href="/w/index.php?title=Special:UrlShortener&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FLinear_discriminant_analysis"><span>Get shortened URL</span></a></li><li id="t-wikibase" class="mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1228929" title="Structured data on this page hosted by Wikidata [g]" accesskey="g"><span>Wikidata item</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-coll-print_export" class="vector-menu mw-portlet mw-portlet-coll-print_export"  >
	<div class="vector-menu-heading">
		Print/export
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="coll-download-as-rl" class="mw-list-item"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Linear_discriminant_analysis&amp;action=show-download-screen" title="Download this page as a PDF file"><span>Download as PDF</span></a></li><li id="t-print" class="mw-list-item"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;printable=yes" title="Printable version of this page [p]" accesskey="p"><span>Printable version</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-wikibase-otherprojects" class="vector-menu mw-portlet mw-portlet-wikibase-otherprojects"  >
	<div class="vector-menu-heading">
		In other projects
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li class="wb-otherproject-link wb-otherproject-commons mw-list-item"><a href="https://commons.wikimedia.org/wiki/Category:Discriminant_analysis" hreflang="en"><span>Wikimedia Commons</span></a></li>
		</ul>
		
	</div>
</div>

</div>

									</div>
				
	</div>
</div>

							</nav>
						</div>
					</div>
				</div>
				<div class="vector-column-end">
					<nav class="vector-page-tools-landmark vector-sticky-pinned-container" aria-label="Page tools">
						<div id="vector-page-tools-pinned-container" class="vector-pinned-container">
			
						</div>
	</nav>
				</div>
				<div id="bodyContent" class="vector-body" aria-labelledby="firstHeading" data-mw-ve-target-container>
					<div class="vector-body-before-content">
							<div class="mw-indicators">
		</div>

						<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
					</div>
					<div id="contentSub"><div id="mw-content-subtitle"></div></div>
					
					
					<div id="mw-content-text" class="mw-body-content mw-content-ltr" lang="en" dir="ltr"><div class="mw-parser-output"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Method used in statistics, pattern recognition, and other fields</div>
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style><div role="note" class="hatnote navigation-not-searchable">Not to be confused with <a href="/wiki/Latent_Dirichlet_allocation" title="Latent Dirichlet allocation">latent Dirichlet allocation</a>.</div>
<p><b>Linear discriminant analysis</b> (<b>LDA</b>), <b>normal discriminant analysis</b> (<b>NDA</b>), or <b>discriminant function analysis</b> is a generalization of <b>Fisher's linear discriminant</b>, a method used in <a href="/wiki/Statistics" title="Statistics">statistics</a> and other fields, to find a <a href="/wiki/Linear_combination" title="Linear combination">linear combination</a> of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a <a href="/wiki/Linear_classifier" title="Linear classifier">linear classifier</a>, or, more commonly, for <a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">dimensionality reduction</a> before later <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a>.
</p><p>LDA is closely related to <a href="/wiki/Analysis_of_variance" title="Analysis of variance">analysis of variance</a> (ANOVA) and <a href="/wiki/Regression_analysis" title="Regression analysis">regression analysis</a>, which also attempt to express one <a href="/wiki/Dependent_variable" class="mw-redirect" title="Dependent variable">dependent variable</a> as a linear combination of other features or measurements.<sup id="cite_ref-Fisher:1936_1-0" class="reference"><a href="#cite_note-Fisher:1936-1">&#91;1&#93;</a></sup><sup id="cite_ref-McLachlan:2004_2-0" class="reference"><a href="#cite_note-McLachlan:2004-2">&#91;2&#93;</a></sup> However, ANOVA uses <a href="/wiki/Categorical_variable" title="Categorical variable">categorical</a> <a href="/wiki/Independent_variables" class="mw-redirect" title="Independent variables">independent variables</a> and a <a href="/wiki/Continuous_variable" class="mw-redirect" title="Continuous variable">continuous</a> <a href="/wiki/Dependent_variable" class="mw-redirect" title="Dependent variable">dependent variable</a>, whereas discriminant analysis has continuous <a href="/wiki/Independent_variables" class="mw-redirect" title="Independent variables">independent variables</a> and a categorical dependent variable (<i>i.e.</i> the class label).<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup> <a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a> and <a href="/wiki/Probit_regression" class="mw-redirect" title="Probit regression">probit regression</a> are more similar to LDA than ANOVA is, as they also explain a categorical variable by the values of continuous independent variables. These other methods are preferable in applications where it is not reasonable to assume that the independent variables are normally distributed, which is a fundamental assumption of the LDA method.
</p><p>LDA is also closely related to <a href="/wiki/Principal_component_analysis" title="Principal component analysis">principal component analysis</a> (PCA) and <a href="/wiki/Factor_analysis" title="Factor analysis">factor analysis</a> in that they both look for linear combinations of variables which best explain the data.<sup id="cite_ref-Martinez:2001_4-0" class="reference"><a href="#cite_note-Martinez:2001-4">&#91;4&#93;</a></sup> LDA explicitly attempts to model the difference between the classes of data. PCA, in contrast, does not take into account any difference in class, and factor analysis builds the feature combinations based on differences rather than similarities. Discriminant analysis is also different from factor analysis in that it is not an interdependence technique: a distinction between independent variables and dependent variables (also called criterion variables) must be made.
</p><p>LDA works when the measurements made on independent variables for each observation are continuous quantities. When dealing with categorical independent variables, the equivalent technique is discriminant correspondence analysis.<sup id="cite_ref-Abdi_2007_5-0" class="reference"><a href="#cite_note-Abdi_2007-5">&#91;5&#93;</a></sup><sup id="cite_ref-Perriere_2003_6-0" class="reference"><a href="#cite_note-Perriere_2003-6">&#91;6&#93;</a></sup>
</p><p>Discriminant analysis is used when groups are known a priori (unlike in <a href="/wiki/Cluster_analysis" title="Cluster analysis">cluster analysis</a>). Each case must have a score on one or more quantitative predictor measures, and a score on a group measure.<sup id="cite_ref-buy_7-0" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup> In simple terms, discriminant function analysis is classification - the act of distributing things into groups, classes or categories of the same type.
</p>
<meta property="mw:PageProp/toc" />
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The original <a href="/wiki/Dichotomy" title="Dichotomy">dichotomous</a> discriminant analysis was developed by Sir <a href="/wiki/Ronald_Fisher" title="Ronald Fisher">Ronald Fisher</a> in 1936.<sup id="cite_ref-cohen_8-0" class="reference"><a href="#cite_note-cohen-8">&#91;8&#93;</a></sup> It is different from an <a href="/wiki/ANOVA" class="mw-redirect" title="ANOVA">ANOVA</a> or <a href="/wiki/MANOVA" class="mw-redirect" title="MANOVA">MANOVA</a>, which is used to predict one (ANOVA) or multiple (MANOVA) continuous dependent variables by one or more independent categorical variables. Discriminant function analysis is useful in determining whether a set of variables is effective in predicting category membership.<sup id="cite_ref-green_9-0" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="LDA_for_two_classes">LDA for two classes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=2" title="Edit section: LDA for two classes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Consider a set of observations <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\vec {x}}"></span> (also called features, attributes, variables or measurements) for each sample of an object or event with known class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"></span>. This set of samples is called the <a href="/wiki/Training_set" class="mw-redirect" title="Training set">training set</a>. The classification problem is then to find a good predictor for the class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"></span> of any sample of the same distribution (not necessarily from the training set) given only an observation <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\vec {x}}"></span>.<sup id="cite_ref-Venables:2002_10-0" class="reference"><a href="#cite_note-Venables:2002-10">&#91;10&#93;</a></sup><sup class="reference nowrap"><span title="Page / location: 338">&#58;&#8202;338&#8202;</span></sup>
</p><p>LDA approaches the problem by assuming that the conditional <a href="/wiki/Probability_density_function" title="Probability density function">probability density functions</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\vec {x}}|y=0)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>y</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\vec {x}}|y=0)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d1e91e3ff4724ab55e76552351b4cc0c00bae85e" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.461ex; height:2.843ex;" alt="p({\vec {x}}|y=0)"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\vec {x}}|y=1)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>y</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\vec {x}}|y=1)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cb01c1539284f1d6a96aaa62447c5128e944a5fd" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.461ex; height:2.843ex;" alt="p({\vec {x}}|y=1)"></span> are both <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">the normal distribution</a> with mean and <a href="/wiki/Covariance" title="Covariance">covariance</a> parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \left({\vec {\mu }}_{0},\Sigma _{0}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>0</mn>
              </mrow>
            </msub>
            <mo>,</mo>
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>0</mn>
              </mrow>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \left({\vec {\mu }}_{0},\Sigma _{0}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a06199f4d32722d66d01c3c12bc66e3df6c77e58" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.031ex; height:2.843ex;" alt="\left({\vec {\mu }}_{0},\Sigma _{0}\right)"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \left({\vec {\mu }}_{1},\Sigma _{1}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>1</mn>
              </mrow>
            </msub>
            <mo>,</mo>
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>1</mn>
              </mrow>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \left({\vec {\mu }}_{1},\Sigma _{1}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d04542286712bfc7f0f79de2bcfd5541dab0e25b" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.031ex; height:2.843ex;" alt="\left({\vec {\mu }}_{1},\Sigma _{1}\right)"></span>, respectively. Under this assumption, the <a href="/wiki/Bayes_classifier" title="Bayes classifier">Bayes-optimal solution</a> is to predict points as being from the second class if the log of the likelihood ratios is bigger than some threshold T, so that:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle ({\vec {x}}-{\vec {\mu }}_{0})^{\mathrm {T} }\Sigma _{0}^{-1}({\vec {x}}-{\vec {\mu }}_{0})-0.5\ln |\Sigma _{0}|-({\vec {x}}-{\vec {\mu }}_{1})^{\mathrm {T} }\Sigma _{1}^{-1}({\vec {x}}-{\vec {\mu }}_{1})+0.5\ln |\Sigma _{1}|\ &gt;\ T}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mn>0.5</mn>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mn>0.5</mn>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mtext>&#xA0;</mtext>
        <mo>&gt;</mo>
        <mtext>&#xA0;</mtext>
        <mi>T</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle ({\vec {x}}-{\vec {\mu }}_{0})^{\mathrm {T} }\Sigma _{0}^{-1}({\vec {x}}-{\vec {\mu }}_{0})-0.5\ln |\Sigma _{0}|-({\vec {x}}-{\vec {\mu }}_{1})^{\mathrm {T} }\Sigma _{1}^{-1}({\vec {x}}-{\vec {\mu }}_{1})+0.5\ln |\Sigma _{1}|\ &gt;\ T}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34f8352326fd367a0dbce05eec6495eed9cdc793" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:78.44ex; height:3.343ex;" alt="{\displaystyle ({\vec {x}}-{\vec {\mu }}_{0})^{\mathrm {T} }\Sigma _{0}^{-1}({\vec {x}}-{\vec {\mu }}_{0})-0.5\ln |\Sigma _{0}|-({\vec {x}}-{\vec {\mu }}_{1})^{\mathrm {T} }\Sigma _{1}^{-1}({\vec {x}}-{\vec {\mu }}_{1})+0.5\ln |\Sigma _{1}|\ &gt;\ T}"></span></dd></dl>
<p>Without any further assumptions, the resulting classifier is referred to as <a href="/wiki/Quadratic_classifier" title="Quadratic classifier">quadratic discriminant analysis</a> (QDA).
</p><p>LDA instead makes the additional simplifying <a href="/wiki/Homoscedastic" class="mw-redirect" title="Homoscedastic">homoscedasticity</a> assumption (<i>i.e.</i> that the class covariances are identical, so <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{0}=\Sigma _{1}=\Sigma }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{0}=\Sigma _{1}=\Sigma }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/89a60bdc5488c601ac4ded1044ae3f5b6bcabedd" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:13.34ex; height:2.509ex;" alt="\Sigma _{0}=\Sigma _{1}=\Sigma "></span>) and that the covariances have full rank.
In this case, several terms cancel:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}^{\mathrm {T} }\Sigma _{0}^{-1}{\vec {x}}={\vec {x}}^{\mathrm {T} }\Sigma _{1}^{-1}{\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>x</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>x</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}^{\mathrm {T} }\Sigma _{0}^{-1}{\vec {x}}={\vec {x}}^{\mathrm {T} }\Sigma _{1}^{-1}{\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/54e6cc0538d6ca28e98b06b2a734ad798252c614" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:19.277ex; height:3.509ex;" alt="{\displaystyle {\vec {x}}^{\mathrm {T} }\Sigma _{0}^{-1}{\vec {x}}={\vec {x}}^{\mathrm {T} }\Sigma _{1}^{-1}{\vec {x}}}"></span></dd>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}^{\mathrm {T} }{\Sigma _{i}}^{-1}{\vec {\mu }}_{i}={{\vec {\mu }}_{i}}^{\mathrm {T} }{\Sigma _{i}}^{-1}{\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>x</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}^{\mathrm {T} }{\Sigma _{i}}^{-1}{\vec {\mu }}_{i}={{\vec {\mu }}_{i}}^{\mathrm {T} }{\Sigma _{i}}^{-1}{\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/42a3d9e81afe46dd7735f760b6950fa93fe45e6b" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:22.619ex; height:3.343ex;" alt="{\displaystyle {\vec {x}}^{\mathrm {T} }{\Sigma _{i}}^{-1}{\vec {\mu }}_{i}={{\vec {\mu }}_{i}}^{\mathrm {T} }{\Sigma _{i}}^{-1}{\vec {x}}}"></span>  because <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7311e26a182cf249a67308c6ceb4d12d2c6896b8" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.478ex; height:2.509ex;" alt="\Sigma _{i}"></span> is <a href="/wiki/Hermitian_matrix" title="Hermitian matrix">Hermitian</a></dd></dl>
<p>and the above decision criterion
becomes a threshold on the <a href="/wiki/Dot_product" title="Dot product">dot product</a>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {x}}&gt;c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>w</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&gt;</mo>
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {x}}&gt;c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7d3479ae0d2b69060eccbf2cc7abaaf56de89630" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:8.518ex; height:2.843ex;" alt="{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {x}}&gt;c}"></span></dd></dl>
<p>for some threshold constant <i>c</i>, where
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}=\Sigma ^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}=\Sigma ^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b58cdf092dbf241d217dbca9b1e16a6335c7b0f" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:18.335ex; height:3.176ex;" alt="{\vec {w}}=\Sigma ^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})"></span></dd>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c={\frac {1}{2}}\,{\vec {w}}^{\mathrm {T} }({\vec {\mu }}_{1}+{\vec {\mu }}_{0})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>w</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>+</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c={\frac {1}{2}}\,{\vec {w}}^{\mathrm {T} }({\vec {\mu }}_{1}+{\vec {\mu }}_{0})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e62c68cfba403b2a3decd8e0ed63ff44ab24af97" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.838ex; width:19.135ex; height:5.176ex;" alt="{\displaystyle c={\frac {1}{2}}\,{\vec {w}}^{\mathrm {T} }({\vec {\mu }}_{1}+{\vec {\mu }}_{0})}"></span></dd></dl>
<p>This means that the criterion of an input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"></span> being in a class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"></span> is purely a function of this linear combination of the known observations.
</p><p>It is often useful to see this conclusion in geometrical terms: the criterion of an input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"></span> being in a class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"></span> is purely a function of projection of multidimensional-space point <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"></span> onto vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\displaystyle {\vec {w}}}"></span> (thus, we only consider its direction). In other words, the observation belongs to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"></span> if corresponding <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"></span> is located on a certain side of a hyperplane perpendicular to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\displaystyle {\vec {w}}}"></span>. The location of the plane is defined by the threshold <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"></span>.
</p>
<h2><span class="mw-headline" id="Assumptions">Assumptions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=3" title="Edit section: Assumptions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The assumptions of discriminant analysis are the same as those for MANOVA. The analysis is quite sensitive to outliers and the size of the smallest group must be larger than the number of predictor variables.<sup id="cite_ref-buy_7-1" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup>
</p>
<ul><li><a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">Multivariate normality</a>: Independent variables are normal for each level of the grouping variable.<sup id="cite_ref-green_9-1" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><sup id="cite_ref-buy_7-2" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li>
<li>Homogeneity of variance/covariance (<a href="/wiki/Homoscedasticity" class="mw-redirect" title="Homoscedasticity">homoscedasticity</a>): Variances among group variables are the same across levels of predictors. Can be tested with <a href="/wiki/Box%27s_M_test" title="Box&#39;s M test">Box's M</a> statistic.<sup id="cite_ref-green_9-2" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> It has been suggested, however, that linear discriminant analysis be used when covariances are equal, and that <a href="/wiki/Quadratic_classifier#Quadratic_discriminant_analysis" title="Quadratic classifier">quadratic discriminant analysis</a> may be used when covariances are not equal.<sup id="cite_ref-buy_7-3" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li>
<li><a href="/wiki/Multicollinearity" title="Multicollinearity">Multicollinearity</a>: Predictive power can decrease with an increased correlation between predictor variables.<sup id="cite_ref-buy_7-4" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li>
<li><a href="/wiki/Statistical_independence" class="mw-redirect" title="Statistical independence">Independence</a>: Participants are assumed to be randomly sampled, and a participant's score on one variable is assumed to be independent of scores on that variable for all other participants.<sup id="cite_ref-green_9-3" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><sup id="cite_ref-buy_7-5" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li></ul>
<p>It has been suggested that discriminant analysis is relatively robust to slight violations of these assumptions,<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup> and it has also been shown that discriminant analysis may still be reliable when using dichotomous variables (where multivariate normality is often violated).<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Discriminant_functions">Discriminant functions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=4" title="Edit section: Discriminant functions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Discriminant analysis works by creating one or more linear combinations of predictors, creating a new <a href="/wiki/Latent_variable" class="mw-redirect" title="Latent variable">latent variable</a> for each function. These functions are called discriminant functions. The number of functions possible is either <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle N_{g}-1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>g</mi>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N_{g}-1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7e37ccc72c1745fa547dbe5249d72e55d71688dd" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:6.89ex; height:2.843ex;" alt="{\displaystyle N_{g}-1}"></span> where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle N_{g}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>g</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N_{g}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3e13540585f557c8bd150cd8236a82f3cf8c153f" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:2.888ex; height:2.843ex;" alt="N_{g}"></span> = number of groups, or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:1.259ex; height:2.009ex;" alt="p"></span> (the number of predictors), whichever is smaller. The first function created maximizes the differences between groups on that function. The second function maximizes differences on that function, but also must not be correlated with the previous function. This continues with subsequent functions with the requirement that the new function not be correlated with any of the previous functions.
</p><p>Given group <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"></span>, with  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbb {R} _{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbb {R} _{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/de8051cf7d3985732207d2c56bca30e1b38b4768" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:2.588ex; height:2.843ex;" alt="{\mathbb  {R}}_{j}"></span>  sets of sample space, there is a discriminant rule such that if <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x\in \mathbb {R} _{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x\in \mathbb {R} _{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/890e192110d0ea0cdc581c699ff30d69fea1a6d9" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:6.758ex; height:2.843ex;" alt="x\in {\mathbb  {R}}_{j}"></span>, then <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x\in j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x\in j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6acaa3c13e02debb505991f99188945c28fb3c73" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:5.128ex; height:2.509ex;" alt="x\in j"></span>. Discriminant analysis then, finds “good” regions of  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbb {R} _{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbb {R} _{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/de8051cf7d3985732207d2c56bca30e1b38b4768" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:2.588ex; height:2.843ex;" alt="{\mathbb  {R}}_{j}"></span> to minimize classification error, therefore leading to a high percent correct classified in the classification table.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup>
</p><p>Each function is given a discriminant score<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2019)">clarification needed</span></a></i>&#93;</sup> to determine how well it predicts group placement. 
</p>
<ul><li>Structure Correlation Coefficients: The correlation between each predictor and the discriminant score of each function. This is a zero-order correlation (i.e., not corrected for the other predictors).<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup></li>
<li>Standardized Coefficients: Each predictor's weight in the linear combination that is the discriminant function.  Like in a regression equation, these coefficients are partial (i.e., corrected for the other predictors). Indicates the unique contribution of each predictor in predicting group assignment.</li>
<li>Functions at Group Centroids: Mean discriminant scores for each grouping variable are given for each function. The farther apart the means are, the less error there will be in classification.</li></ul>
<h2><span class="mw-headline" id="Discrimination_rules">Discrimination rules</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=5" title="Edit section: Discrimination rules">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Maximum_likelihood" class="mw-redirect" title="Maximum likelihood">Maximum likelihood</a>: Assigns <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"></span> to the group that maximizes population (group) density.<sup id="cite_ref-har_15-0" class="reference"><a href="#cite_note-har-15">&#91;15&#93;</a></sup></li>
<li>Bayes Discriminant Rule: Assigns <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"></span> to the group that maximizes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \pi _{i}f_{i}(x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03C0;<!-- π --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \pi _{i}f_{i}(x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6f35c70a2c329679558c8589c3f45f0db95d1194" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:7.203ex; height:2.843ex;" alt="\pi _{i}f_{i}(x)"></span>, where <i>π<sub>i</sub></i> represents the <a href="/wiki/Prior_probability" title="Prior probability">prior probability</a> of that classification, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f_{i}(x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{i}(x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76860d42459c0fb06c73293d257cf90698390262" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.078ex; height:2.843ex;" alt="f_{i}(x)"></span> represents the population density.<sup id="cite_ref-har_15-1" class="reference"><a href="#cite_note-har-15">&#91;15&#93;</a></sup></li>
<li><a href="#Fisher&#39;s_linear_discriminant">Fisher's linear discriminant rule</a>: Maximizes the ratio between <i>SS</i><sub>between</sub> and <i>SS</i><sub>within</sub>, and finds a linear combination of the predictors to predict group.<sup id="cite_ref-har_15-2" class="reference"><a href="#cite_note-har-15">&#91;15&#93;</a></sup></li></ul>
<h2><span class="mw-headline" id="Eigenvalues">Eigenvalues</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=6" title="Edit section: Eigenvalues">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>An <a href="/wiki/Eigenvalues_and_eigenvectors" title="Eigenvalues and eigenvectors">eigenvalue</a> in discriminant analysis is the characteristic root of each function.<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2012)">clarification needed</span></a></i>&#93;</sup> It is an indication of how well that function differentiates the groups, where the larger the eigenvalue, the better the function differentiates.<sup id="cite_ref-buy_7-6" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup> This however, should be interpreted with caution, as eigenvalues have no upper limit.<sup id="cite_ref-green_9-4" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><sup id="cite_ref-buy_7-7" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup>
	The eigenvalue can be viewed as a ratio of <i>SS</i><sub>between</sub> and <i>SS</i><sub>within</sub> as in ANOVA when the dependent variable is the discriminant function, and the groups are the levels of the <a href="/wiki/Instrumental_variable" class="mw-redirect" title="Instrumental variable">IV</a><sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2012)">clarification needed</span></a></i>&#93;</sup>.<sup id="cite_ref-green_9-5" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> This means that the largest eigenvalue is associated with the first function, the second largest with the second, etc..
</p>
<h2><span class="mw-headline" id="Effect_size">Effect size</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=7" title="Edit section: Effect size">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Some suggest the use of eigenvalues as <a href="/wiki/Effect_size" title="Effect size">effect size</a> measures, however, this is generally not supported.<sup id="cite_ref-green_9-6" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> Instead, the <a href="/wiki/Canonical_correlation" title="Canonical correlation">canonical correlation</a> is the preferred measure of effect size. It is similar to the eigenvalue, but is the square root of the ratio of <i>SS</i><sub>between</sub> and <i>SS</i><sub>total</sub>. It is the correlation between groups and the function.<sup id="cite_ref-green_9-7" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> 
	Another popular measure of effect size is the percent of variance<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2012)">clarification needed</span></a></i>&#93;</sup> for each function.  This is calculated by: (<i>λ<sub>x</sub>/Σλ<sub>i</sub></i>) X 100 where <i>λ<sub>x</sub></i> is the eigenvalue for the function and Σ<i>λ<sub>i</sub></i> is the sum of all eigenvalues. This tells us how strong the prediction is for that particular function compared to the others.<sup id="cite_ref-green_9-8" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> 
	Percent correctly classified can also be analyzed as an effect size. The kappa value can describe this while correcting for chance agreement.<sup id="cite_ref-green_9-9" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><span class="cleanup-needed-content" style="padding-left:0.1em; padding-right:0.1em; color:#595959; border:1px solid #DDD;">Kappa normalizes across all categorizes rather than biased by a significantly good or poorly performing classes.</span><sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="Kappa normalizes across all categorizes rather than biased by a significantly good or poorly performing classes (April 2012)">clarification needed</span></a></i>&#93;</sup><sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Canonical_discriminant_analysis_for_k_classes">Canonical discriminant analysis for <i>k</i> classes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=8" title="Edit section: Canonical discriminant analysis for k classes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Canonical discriminant analysis (CDA) finds axes (<i>k</i>&#160;−&#160;1 <a href="/wiki/Canonical_coordinates" title="Canonical coordinates">canonical coordinates</a>, <i>k</i> being the number of classes) that best separate the categories. These linear functions are uncorrelated and define, in effect, an optimal <i>k</i>&#160;−&#160;1 space through the <i>n</i>-dimensional cloud of data that best separates (the projections in that space of) the <i>k</i> groups. See “<a href="#Multiclass_LDA">Multiclass LDA</a>” for details below.
</p>
<h2><span id="Fisher.27s_linear_discriminant"></span><span class="mw-headline" id="Fisher's_linear_discriminant">Fisher's linear discriminant</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=9" title="Edit section: Fisher&#039;s linear discriminant">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The terms <i>Fisher's linear discriminant</i> and <i>LDA</i> are often used interchangeably, although <a href="/wiki/Ronald_A._Fisher" class="mw-redirect" title="Ronald A. Fisher">Fisher's</a> original article<sup id="cite_ref-Fisher:1936_1-1" class="reference"><a href="#cite_note-Fisher:1936-1">&#91;1&#93;</a></sup> actually describes a slightly different discriminant, which does not make some of the assumptions of LDA such as <a href="/wiki/Normal_distribution" title="Normal distribution">normally distributed</a> classes or equal class <a href="/wiki/Covariance" title="Covariance">covariances</a>.
</p><p>Suppose two classes of observations have <a href="/wiki/Mean" title="Mean">means</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {\mu }}_{0},{\vec {\mu }}_{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {\mu }}_{0},{\vec {\mu }}_{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7d75b644ba086ca4f0c46c8f8a542ea8659350a4" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.946ex; height:2.843ex;" alt="{\vec {\mu }}_{0},{\vec {\mu }}_{1}"></span> and covariances <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{0},\Sigma _{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{0},\Sigma _{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4e7729961ead52abb59f9798f2d88bdb3cc9bced" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:6.499ex; height:2.509ex;" alt="\Sigma _{0},\Sigma _{1}"></span>. Then the linear combination of features <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>w</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/69fe8d2a76d6bc81fd291e40d7bbfa314d703fb3" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:4.413ex; height:2.843ex;" alt="{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {x}}}"></span> will have <a href="/wiki/Mean" title="Mean">means</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {\mu }}_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>w</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {\mu }}_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8f821ab2927e9337d693b8242c2f02f8970889e5" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.284ex; height:3.343ex;" alt="{\displaystyle {\vec {w}}^{\mathrm {T} }{\vec {\mu }}_{i}}"></span> and <a href="/wiki/Variance" title="Variance">variances</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}^{\mathrm {T} }\Sigma _{i}{\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>w</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}^{\mathrm {T} }\Sigma _{i}{\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dc0491e13ca6f459e3babf7c63af30cba2af024e" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:7.225ex; height:3.176ex;" alt="{\displaystyle {\vec {w}}^{\mathrm {T} }\Sigma _{i}{\vec {w}}}"></span> for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i=0,1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i=0,1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6b152b69b98c4244dd0c690c8ef74740df7fd343" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:7.26ex; height:2.509ex;" alt="i=0,1"></span>. Fisher defined the separation between these two <a href="/wiki/Probability_distribution" title="Probability distribution">distributions</a> to be the ratio of the variance between the classes to the variance within the classes:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle S={\frac {\sigma _{\text{between}}^{2}}{\sigma _{\text{within}}^{2}}}={\frac {({\vec {w}}\cdot {\vec {\mu }}_{1}-{\vec {w}}\cdot {\vec {\mu }}_{0})^{2}}{{\vec {w}}^{\mathrm {T} }\Sigma _{1}{\vec {w}}+{\vec {w}}^{\mathrm {T} }\Sigma _{0}{\vec {w}}}}={\frac {({\vec {w}}\cdot ({\vec {\mu }}_{1}-{\vec {\mu }}_{0}))^{2}}{{\vec {w}}^{\mathrm {T} }(\Sigma _{0}+\Sigma _{1}){\vec {w}}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>S</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msubsup>
              <mi>&#x03C3;<!-- σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>between</mtext>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msubsup>
            <msubsup>
              <mi>&#x03C3;<!-- σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>within</mtext>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msubsup>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>&#x2212;<!-- − --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <msup>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </mrow>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="normal">T</mi>
                  </mrow>
                </mrow>
              </msup>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>+</mo>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="normal">T</mi>
                  </mrow>
                </mrow>
              </msup>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>&#x2212;<!-- − --></mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
              <msup>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </mrow>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="normal">T</mi>
                  </mrow>
                </mrow>
              </msup>
              <mo stretchy="false">(</mo>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle S={\frac {\sigma _{\text{between}}^{2}}{\sigma _{\text{within}}^{2}}}={\frac {({\vec {w}}\cdot {\vec {\mu }}_{1}-{\vec {w}}\cdot {\vec {\mu }}_{0})^{2}}{{\vec {w}}^{\mathrm {T} }\Sigma _{1}{\vec {w}}+{\vec {w}}^{\mathrm {T} }\Sigma _{0}{\vec {w}}}}={\frac {({\vec {w}}\cdot ({\vec {\mu }}_{1}-{\vec {\mu }}_{0}))^{2}}{{\vec {w}}^{\mathrm {T} }(\Sigma _{0}+\Sigma _{1}){\vec {w}}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/111ae0bd4d327535e9245430e82656ad13ebd6d6" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -3.171ex; width:54.274ex; height:7.343ex;" alt="{\displaystyle S={\frac {\sigma _{\text{between}}^{2}}{\sigma _{\text{within}}^{2}}}={\frac {({\vec {w}}\cdot {\vec {\mu }}_{1}-{\vec {w}}\cdot {\vec {\mu }}_{0})^{2}}{{\vec {w}}^{\mathrm {T} }\Sigma _{1}{\vec {w}}+{\vec {w}}^{\mathrm {T} }\Sigma _{0}{\vec {w}}}}={\frac {({\vec {w}}\cdot ({\vec {\mu }}_{1}-{\vec {\mu }}_{0}))^{2}}{{\vec {w}}^{\mathrm {T} }(\Sigma _{0}+\Sigma _{1}){\vec {w}}}}}"></span></dd></dl>
<p>This measure is, in some sense, a measure of the <a href="/wiki/Signal-to-noise_ratio" title="Signal-to-noise ratio">signal-to-noise ratio</a> for the class labelling. It can be shown that the maximum separation occurs when
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\propto (\Sigma _{0}+\Sigma _{1})^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x221D;<!-- ∝ --></mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>+</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\propto (\Sigma _{0}+\Sigma _{1})^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ed939999cb7d18ccdd9ebe10120a0abe6f960edf" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:26.771ex; height:3.176ex;" alt="{\vec {w}}\propto (\Sigma _{0}+\Sigma _{1})^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})"></span></dd></dl>
<p>When the assumptions of LDA are satisfied, the above equation is equivalent to LDA.
</p>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Fisher2classes.png" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Fisher2classes.png/220px-Fisher2classes.png" decoding="async" width="220" height="165" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Fisher2classes.png/330px-Fisher2classes.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Fisher2classes.png/440px-Fisher2classes.png 2x" data-file-width="640" data-file-height="480" /></a><figcaption>Fisher's Linear Discriminant visualised as an axis</figcaption></figure>
<p>Be sure to note that the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"></span> is the <a href="/wiki/Surface_normal" class="mw-redirect" title="Surface normal">normal</a> to the discriminant <a href="/wiki/Hyperplane" title="Hyperplane">hyperplane</a>. As an example, in a two dimensional problem, the line that best divides the two groups is perpendicular to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"></span>.
</p><p>Generally, the data points to be discriminated are projected onto <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"></span>; then the threshold that best separates the data is chosen from analysis of the one-dimensional distribution. There is no general rule for the threshold. However, if projections of points from both classes exhibit approximately the same distributions, a good choice would be the hyperplane between projections of the two means, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7ee2f8982c2052f90d40a2f67adac1057fda6eb5" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.799ex; height:2.843ex;" alt="{\vec {w}}\cdot {\vec {\mu }}_{0}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dd3e65a898afcb1def61eb279b6d36ca2bb39040" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.799ex; height:2.843ex;" alt="{\vec {w}}\cdot {\vec {\mu }}_{1}"></span>. In this case the parameter c in threshold condition <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {x}}&gt;c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&gt;</mo>
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {x}}&gt;c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8fe25a6aa1b34af1442727dbb7827294f90102ee" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:8.778ex; height:2.343ex;" alt="{\vec {w}}\cdot {\vec {x}}&gt;c"></span> can be found explicitly:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c={\vec {w}}\cdot {\frac {1}{2}}({\vec {\mu }}_{0}+{\vec {\mu }}_{1})={\frac {1}{2}}{\vec {\mu }}_{1}^{\mathrm {T} }\Sigma _{1}^{-1}{\vec {\mu }}_{1}-{\frac {1}{2}}{\vec {\mu }}_{0}^{\mathrm {T} }\Sigma _{0}^{-1}{\vec {\mu }}_{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>+</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <msubsup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msubsup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <msubsup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msubsup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c={\vec {w}}\cdot {\frac {1}{2}}({\vec {\mu }}_{0}+{\vec {\mu }}_{1})={\frac {1}{2}}{\vec {\mu }}_{1}^{\mathrm {T} }\Sigma _{1}^{-1}{\vec {\mu }}_{1}-{\frac {1}{2}}{\vec {\mu }}_{0}^{\mathrm {T} }\Sigma _{0}^{-1}{\vec {\mu }}_{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ff573cffb698a1721dd2c7a38581397caae4fbab" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -1.838ex; width:47.519ex; height:5.176ex;" alt="{\displaystyle c={\vec {w}}\cdot {\frac {1}{2}}({\vec {\mu }}_{0}+{\vec {\mu }}_{1})={\frac {1}{2}}{\vec {\mu }}_{1}^{\mathrm {T} }\Sigma _{1}^{-1}{\vec {\mu }}_{1}-{\frac {1}{2}}{\vec {\mu }}_{0}^{\mathrm {T} }\Sigma _{0}^{-1}{\vec {\mu }}_{0}}"></span>.</dd></dl>
<p><a href="/wiki/Otsu%27s_method" title="Otsu&#39;s method">Otsu's method</a> is related to Fisher's linear discriminant, and was created to binarize the histogram of pixels in a grayscale image by optimally picking the black/white threshold that minimizes intra-class variance and maximizes inter-class variance within/between grayscales assigned to black and white pixel classes.
</p>
<h2><span class="mw-headline" id="Multiclass_LDA">Multiclass LDA</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=10" title="Edit section: Multiclass LDA">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:4class3ddiscriminant.png" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/4/41/4class3ddiscriminant.png/220px-4class3ddiscriminant.png" decoding="async" width="220" height="170" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/41/4class3ddiscriminant.png/330px-4class3ddiscriminant.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/41/4class3ddiscriminant.png/440px-4class3ddiscriminant.png 2x" data-file-width="640" data-file-height="494" /></a><figcaption>Visualisation for one-versus-all LDA axes for 4 classes in 3d</figcaption></figure>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:3dProjections.png" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/3dProjections.png/220px-3dProjections.png" decoding="async" width="220" height="165" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/3dProjections.png/330px-3dProjections.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/4c/3dProjections.png/440px-3dProjections.png 2x" data-file-width="640" data-file-height="480" /></a><figcaption>Projections along linear discriminant axes for 4 classes</figcaption></figure>
<p>In the case where there are more than two classes, the analysis used in the derivation of the Fisher discriminant can be extended to find a <a href="/wiki/Linear_subspace" title="Linear subspace">subspace</a> which appears to contain all of the class variability.<sup id="cite_ref-garson_17-0" class="reference"><a href="#cite_note-garson-17">&#91;17&#93;</a></sup> This generalization is due to <a href="/wiki/C._R._Rao" title="C. R. Rao">C. R. Rao</a>.<sup id="cite_ref-Rao:1948_18-0" class="reference"><a href="#cite_note-Rao:1948-18">&#91;18&#93;</a></sup> Suppose that each of C classes has a mean <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mu _{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mu _{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dea0a0293841cce9eef98b55e53a92b82ae59ee4" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:2.201ex; height:2.176ex;" alt="\mu _{i}"></span> and the same covariance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9e1f558f53cda207614abdf90162266c70bc5c1e" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.678ex; height:2.176ex;" alt="\Sigma "></span>. Then the scatter between class variability may be defined by the sample covariance of the class means
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{b}={\frac {1}{C}}\sum _{i=1}^{C}(\mu _{i}-\mu )(\mu _{i}-\mu )^{\mathrm {T} }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>C</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </munderover>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03BC;<!-- μ --></mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03BC;<!-- μ --></mi>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="normal">T</mi>
            </mrow>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{b}={\frac {1}{C}}\sum _{i=1}^{C}(\mu _{i}-\mu )(\mu _{i}-\mu )^{\mathrm {T} }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/678e1651aba70143647ddc6d9b54d600b7664730" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -3.005ex; width:29.983ex; height:7.343ex;" alt="{\displaystyle \Sigma _{b}={\frac {1}{C}}\sum _{i=1}^{C}(\mu _{i}-\mu )(\mu _{i}-\mu )^{\mathrm {T} }}"></span></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mu }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BC;<!-- μ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mu }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9fd47b2a39f7a7856952afec1f1db72c67af6161" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:1.402ex; height:2.176ex;" alt="\mu "></span> is the mean of the class means. The class separation in a direction <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"></span> in this case will be given by
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle S={\frac {{\vec {w}}^{\mathrm {T} }\Sigma _{b}{\vec {w}}}{{\vec {w}}^{\mathrm {T} }\Sigma {\vec {w}}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>S</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="normal">T</mi>
                  </mrow>
                </mrow>
              </msup>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>b</mi>
                </mrow>
              </msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="normal">T</mi>
                  </mrow>
                </mrow>
              </msup>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle S={\frac {{\vec {w}}^{\mathrm {T} }\Sigma _{b}{\vec {w}}}{{\vec {w}}^{\mathrm {T} }\Sigma {\vec {w}}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6658be1b02c96b5499cc43a81113545169db643a" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -2.505ex; width:12.797ex; height:6.509ex;" alt="{\displaystyle S={\frac {{\vec {w}}^{\mathrm {T} }\Sigma _{b}{\vec {w}}}{{\vec {w}}^{\mathrm {T} }\Sigma {\vec {w}}}}}"></span></dd></dl>
<p>This means that when <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"></span> is an <a href="/wiki/Eigenvector" class="mw-redirect" title="Eigenvector">eigenvector</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma ^{-1}\Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma ^{-1}\Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bed8bc5902c52eeda946a8cd494c56b2a793da5e" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:6.627ex; height:3.009ex;" alt="\Sigma ^{-1}\Sigma _{b}"></span> the separation will be equal to the corresponding <a href="/wiki/Eigenvalue" class="mw-redirect" title="Eigenvalue">eigenvalue</a>.
</p><p>If <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma ^{-1}\Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma ^{-1}\Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bed8bc5902c52eeda946a8cd494c56b2a793da5e" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:6.627ex; height:3.009ex;" alt="\Sigma ^{-1}\Sigma _{b}"></span> is diagonalizable, the variability between features will be contained in the subspace spanned by the eigenvectors corresponding to the <i>C</i>&#160;−&#160;1 largest eigenvalues (since <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e155673de62e59fff0442b3c28f42ff0113cb222" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.616ex; height:2.509ex;" alt="\Sigma _{b}"></span> is of rank <i>C</i>&#160;−&#160;1 at most). These eigenvectors are primarily used in feature reduction, as in PCA. The eigenvectors corresponding to the smaller eigenvalues will tend to be very sensitive to the exact choice of training data, and it is often necessary to use regularisation as described in the next section.
</p><p>If classification is required, instead of <a href="/wiki/Dimension_reduction" class="mw-redirect" title="Dimension reduction">dimension reduction</a>, there are a number of alternative techniques available. For instance, the classes may be partitioned, and a standard Fisher discriminant or LDA used to classify each partition. A common example of this is "one against the rest" where the points from one class are put in one group, and everything else in the other, and then LDA applied. This will result in C classifiers, whose results are combined. Another common
method is pairwise classification, where a new classifier is created for each pair of classes (giving <i>C</i>(<i>C</i>&#160;−&#160;1)/2 classifiers in total), with the individual classifiers combined to produce a final classification.
</p>
<h2><span class="mw-headline" id="Incremental_LDA">Incremental LDA</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=11" title="Edit section: Incremental LDA">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The typical implementation of the LDA technique requires that all the samples are available in advance. However,  there are situations where the entire data set is not available and the input data are observed as a stream. In this case, it is desirable for the LDA feature extraction to have the ability to update the computed LDA features by observing the new samples without running the algorithm on the whole data set. For example, in many real-time applications such as mobile robotics or on-line face recognition, it is important to update the extracted LDA features as soon as new observations are available. An LDA feature extraction technique that can update the LDA features by simply observing new samples is an <i>incremental LDA algorithm</i>, and this idea has been extensively studied over the last two decades.<sup id="cite_ref-:0_19-0" class="reference"><a href="#cite_note-:0-19">&#91;19&#93;</a></sup> Chatterjee and Roychowdhury proposed an incremental self-organized LDA algorithm for updating the LDA features.<sup id="cite_ref-:1_20-0" class="reference"><a href="#cite_note-:1-20">&#91;20&#93;</a></sup> In other work, Demir and Ozmehmet proposed online local learning algorithms for updating LDA features incrementally using error-correcting and the Hebbian learning rules.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">&#91;21&#93;</a></sup> Later, Aliyari <i>et a</i>l. derived fast incremental algorithms to update the LDA features by observing the new samples.<sup id="cite_ref-:0_19-1" class="reference"><a href="#cite_note-:0-19">&#91;19&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Practical_use">Practical use</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=12" title="Edit section: Practical use">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In practice, the class means and covariances are not known. They can, however, be estimated from the training set. Either the <a href="/wiki/Maximum_likelihood_estimation" title="Maximum likelihood estimation">maximum likelihood estimate</a> or the <a href="/wiki/Maximum_a_posteriori" class="mw-redirect" title="Maximum a posteriori">maximum a posteriori</a> estimate may be used in place of the exact value in the above equations. Although the estimates of the covariance may be considered optimal in some sense, this does not mean that the resulting discriminant obtained by substituting these values is optimal in any sense, even if the assumption of normally distributed classes is correct.
</p><p>Another complication in applying LDA and Fisher's discriminant to real data occurs when the number of measurements of each sample (i.e., the dimensionality of each data vector) exceeds the number of samples in each class.<sup id="cite_ref-Martinez:2001_4-1" class="reference"><a href="#cite_note-Martinez:2001-4">&#91;4&#93;</a></sup> In this case, the covariance estimates do not have full rank, and so cannot be inverted. There are a number of ways to deal with this. One is to use a <a href="/wiki/Pseudo_inverse" class="mw-redirect" title="Pseudo inverse">pseudo inverse</a> instead of the usual matrix inverse in the above formulae. However, better numeric stability may be achieved by first projecting the problem onto the subspace spanned by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e155673de62e59fff0442b3c28f42ff0113cb222" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.616ex; height:2.509ex;" alt="\Sigma _{b}"></span>.<sup id="cite_ref-22" class="reference"><a href="#cite_note-22">&#91;22&#93;</a></sup>
Another strategy to deal with small sample size is to use a <a href="/wiki/Shrinkage_estimator" class="mw-redirect" title="Shrinkage estimator">shrinkage estimator</a> of the covariance matrix, which
can be expressed mathematically as
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma =(1-\lambda )\Sigma +\lambda I\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
        <mo>=</mo>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03BB;<!-- λ --></mi>
        <mo stretchy="false">)</mo>
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
        <mo>+</mo>
        <mi>&#x03BB;<!-- λ --></mi>
        <mi>I</mi>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma =(1-\lambda )\Sigma +\lambda I\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/64bc6ee831988f828bf12487ce2d62a4fc45e2ad" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:19.376ex; height:2.843ex;" alt="\Sigma =(1-\lambda )\Sigma +\lambda I\,"></span></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle I}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>I</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle I}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/535ea7fc4134a31cbe2251d9d3511374bc41be9f" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.172ex; height:2.176ex;" alt="I"></span> is the identity matrix, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \lambda }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BB;<!-- λ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \lambda }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;" alt="\lambda "></span> is the <i>shrinkage intensity</i> or <i>regularisation parameter</i>.
This leads to the framework of regularized discriminant analysis<sup id="cite_ref-Friedman:2001_23-0" class="reference"><a href="#cite_note-Friedman:2001-23">&#91;23&#93;</a></sup> or shrinkage discriminant analysis.<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup>
</p><p>Also, in many practical cases linear discriminants are not suitable. LDA and Fisher's discriminant can be extended for use in non-linear classification via the <a href="/wiki/Kernel_trick" class="mw-redirect" title="Kernel trick">kernel trick</a>. Here, the original observations are effectively mapped into a higher dimensional non-linear space. Linear classification in this non-linear space is then equivalent to non-linear classification in the original space. The most commonly used example of this is the <a href="/wiki/Kernel_Fisher_discriminant_analysis" title="Kernel Fisher discriminant analysis">kernel Fisher discriminant</a>.
</p><p>LDA can be generalized to <a href="/wiki/Multiple_discriminant_analysis" title="Multiple discriminant analysis">multiple discriminant analysis</a>, where <i>c</i> becomes a <a href="/wiki/Categorical_variable" title="Categorical variable">categorical variable</a> with <i>N</i> possible states, instead of only two. Analogously, if the class-conditional densities <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\vec {x}}\mid c=i)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>c</mi>
        <mo>=</mo>
        <mi>i</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\vec {x}}\mid c=i)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ebdf44d9590830d518013f4dc56163d79940f530" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:11.243ex; height:2.843ex;" alt="{\displaystyle p({\vec {x}}\mid c=i)}"></span> are normal with shared covariances, the <a href="/wiki/Sufficient_statistic" title="Sufficient statistic">sufficient statistic</a> for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle P(c\mid {\vec {x}})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>c</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(c\mid {\vec {x}})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/09592196975f053db376553a76bd452b5b246455" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:7.828ex; height:2.843ex;" alt="{\displaystyle P(c\mid {\vec {x}})}"></span> are the values of <i>N</i> projections, which are the <a href="/wiki/Linear_subspace" title="Linear subspace">subspace</a> spanned by the <i>N</i> means, <a href="/wiki/Affine_transformation" title="Affine transformation">affine projected</a> by the inverse covariance matrix. These projections can be found by solving a <a href="/wiki/Eigendecomposition_of_a_matrix#Generalized_eigenvalue_problem" title="Eigendecomposition of a matrix">generalized eigenvalue problem</a>, where the numerator is the covariance matrix formed by treating the means as the samples, and the denominator is the shared covariance matrix. See “<a href="#Multiclass_LDA">Multiclass LDA</a>” above for details.
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=13" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In addition to the examples given below, LDA is applied in <a href="/wiki/Positioning_(marketing)" title="Positioning (marketing)">positioning</a> and <a href="/wiki/Product_management" title="Product management">product management</a>.
</p>
<h3><span class="mw-headline" id="Bankruptcy_prediction">Bankruptcy prediction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=14" title="Edit section: Bankruptcy prediction">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In <a href="/wiki/Bankruptcy_prediction" title="Bankruptcy prediction">bankruptcy prediction</a> based on accounting ratios and other financial variables, linear discriminant analysis was the first statistical method applied to systematically explain which firms entered bankruptcy vs. survived. Despite limitations including known nonconformance of accounting ratios to the normal distribution assumptions of LDA, <a href="/wiki/Edward_Altman" title="Edward Altman">Edward Altman</a>'s <a href="/wiki/Z-Score_Financial_Analysis_Tool" class="mw-redirect" title="Z-Score Financial Analysis Tool">1968 model</a><sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> is still a leading model in practical applications.<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup><sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup><sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Face_recognition">Face recognition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=15" title="Edit section: Face recognition">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In computerised <a href="/wiki/Facial_recognition_system" title="Facial recognition system">face recognition</a>, each face is represented by a large number of pixel values. Linear discriminant analysis is primarily used here to reduce the number of features to a more manageable number before classification. Each of the new dimensions is a linear combination of pixel values, which form a template. The linear combinations obtained using Fisher's linear discriminant are called <i>Fisher faces</i>, while those obtained using the related <a href="/wiki/Principal_component_analysis" title="Principal component analysis">principal component analysis</a> are called <i><a href="/wiki/Eigenfaces" class="mw-redirect" title="Eigenfaces">eigenfaces</a></i>.
</p>
<h3><span class="mw-headline" id="Marketing">Marketing</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=16" title="Edit section: Marketing">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In <a href="/wiki/Marketing" title="Marketing">marketing</a>, discriminant analysis was once often used to determine the factors which distinguish different types of customers and/or products on the basis of surveys or other forms of collected data. <a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a> or other methods are now more commonly used. The use of discriminant analysis in marketing can be described by the following steps:
</p>
<ol><li>Formulate the problem and gather data—Identify the <a href="/wiki/Social_salience" title="Social salience">salient</a> attributes consumers use to evaluate products in this category—Use <a href="/wiki/Quantitative_marketing_research" title="Quantitative marketing research">quantitative marketing research</a> techniques (such as <a href="/wiki/Statistical_survey" class="mw-redirect" title="Statistical survey">surveys</a>) to collect data from a sample of potential customers concerning their ratings of all the product attributes. The data collection stage is usually done by marketing research professionals. Survey questions ask the respondent to rate a product from one to five (or 1 to 7, or 1 to 10) on a range of attributes chosen by the researcher. Anywhere from five to twenty attributes are chosen. They could include things like: ease of use, weight, accuracy, durability, colourfulness, price, or size. The attributes chosen will vary depending on the product being studied. The same question is asked about all the products in the study. The data for multiple products is codified and input into a statistical program such as <a href="/wiki/R_language" class="mw-redirect" title="R language">R</a>, <a href="/wiki/SPSS" title="SPSS">SPSS</a> or <a href="/wiki/SAS_programming_language" class="mw-redirect" title="SAS programming language">SAS</a>. (This step is the same as in Factor analysis).</li>
<li>Estimate the Discriminant Function Coefficients and determine the statistical significance and validity—Choose the appropriate discriminant analysis method. The direct method involves estimating the discriminant function so that all the predictors are assessed simultaneously. The <a href="/wiki/Stepwise_regression" title="Stepwise regression">stepwise method</a> enters the predictors sequentially. The two-group method should be used when the dependent variable has two categories or states. The multiple discriminant method is used when the dependent variable has three or more categorical states. Use <a href="/wiki/Wilks%27_lambda_distribution" class="mw-redirect" title="Wilks&#39; lambda distribution">Wilks's Lambda</a> to test for significance in SPSS or F stat in SAS. The most common method used to test validity is to split the sample into an estimation or analysis sample, and a validation or holdout sample. The estimation sample is used in constructing the discriminant function. The validation sample is used to construct a classification matrix which contains the number of correctly classified and incorrectly classified cases. The percentage of correctly classified cases is called the <i>hit ratio</i>.</li>
<li>Plot the results on a two dimensional map, define the dimensions, and interpret the results. The statistical program (or a related module) will map the results. The map will plot each product (usually in two-dimensional space). The distance of products to each other indicate either how different they are. The dimensions must be labelled by the researcher. This requires subjective judgement and is often very challenging. See <a href="/wiki/Perceptual_mapping" title="Perceptual mapping">perceptual mapping</a>.</li></ol>
<h3><span class="mw-headline" id="Biomedical_studies">Biomedical studies</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=17" title="Edit section: Biomedical studies">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The main application of discriminant analysis in medicine is the assessment of severity state of a patient and prognosis of disease outcome. For example, during retrospective analysis, patients are divided into groups according to severity of disease – mild, moderate and severe form. Then results of clinical and laboratory analyses are studied in order to reveal variables which are statistically different in studied groups. Using these variables, discriminant functions are built which help to objectively classify disease in a future patient into mild, moderate or severe form.
</p><p>In biology, similar principles are used in order to classify and define groups of different biological objects, for example, to define phage types of Salmonella enteritidis based on Fourier transform infrared spectra,<sup id="cite_ref-29" class="reference"><a href="#cite_note-29">&#91;29&#93;</a></sup> to detect animal source of <i>Escherichia coli</i> studying its virulence factors<sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;30&#93;</a></sup> etc.
</p>
<h3><span class="mw-headline" id="Earth_science">Earth science</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=18" title="Edit section: Earth science">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>This method can be used to <span class="cleanup-needed-content" style="padding-left:0.1em; padding-right:0.1em; color:#595959; border:1px solid #DDD;">separate the alteration zones</span><sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="separate what, where? (May 2021)">clarification needed</span></a></i>&#93;</sup>. For example, when different data from various zones are available, discriminant analysis can find the pattern within the data and classify it effectively.<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Comparison_to_logistic_regression">Comparison to logistic regression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=19" title="Edit section: Comparison to logistic regression">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Discriminant function analysis is very similar to <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, and both can be used to answer the same research questions.<sup id="cite_ref-green_9-10" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> Logistic regression does not have as many assumptions and restrictions as discriminant analysis. However, when discriminant analysis’ assumptions are met, it is more powerful than logistic regression.<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;32&#93;</a></sup> Unlike logistic regression, discriminant analysis can be used with small sample sizes. It has been shown that when sample sizes are equal, and homogeneity of variance/covariance holds, discriminant analysis is more accurate.<sup id="cite_ref-buy_7-8" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup> Despite all these advantages, logistic regression has none-the-less become the common choice, since the assumptions of discriminant analysis are rarely met.<sup id="cite_ref-cohen_8-1" class="reference"><a href="#cite_note-cohen-8">&#91;8&#93;</a></sup><sup id="cite_ref-buy_7-9" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Linear_discriminant_in_high_dimension">Linear discriminant in high dimension</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=20" title="Edit section: Linear discriminant in high dimension">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Geometric anomalies in higher dimensions lead to the well-known <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>. Nevertheless, proper utilization of <a href="/wiki/Concentration_of_measure" title="Concentration of measure">concentration of measure</a> phenomena can make computation easier.<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup> An important case of these  <a href="/wiki/Curse_of_dimensionality#Blessing_of_dimensionality" title="Curse of dimensionality"><i>blessing of dimensionality</i></a> phenomena was highlighted by Donoho and Tanner: if a sample is essentially high-dimensional then each point can be separated from the rest of the sample by linear inequality, with high probability, even for exponentially large samples.<sup id="cite_ref-34" class="reference"><a href="#cite_note-34">&#91;34&#93;</a></sup> These linear inequalities can be selected in the standard (Fisher's) form of the linear discriminant for a rich family of probability distribution.<sup id="cite_ref-35" class="reference"><a href="#cite_note-35">&#91;35&#93;</a></sup> In particular, such theorems are proven for <a href="/wiki/Logarithmically_concave_measure" title="Logarithmically concave measure">log-concave</a> distributions including <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multidimensional normal distribution</a> (the proof is based on the concentration inequalities for log-concave measures<sup id="cite_ref-36" class="reference"><a href="#cite_note-36">&#91;36&#93;</a></sup>) and for product measures on a multidimensional cube (this is proven using <a href="/wiki/Talagrand%27s_concentration_inequality" title="Talagrand&#39;s concentration inequality">Talagrand's concentration inequality</a> for product probability spaces). Data separability by classical linear discriminants simplifies the problem of error correction for <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> systems in high dimension.<sup id="cite_ref-GMT2019_37-0" class="reference"><a href="#cite_note-GMT2019-37">&#91;37&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=21" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Data_mining" title="Data mining">Data mining</a></li>
<li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision tree learning</a></li>
<li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="/wiki/Kernel_Fisher_discriminant_analysis" title="Kernel Fisher discriminant analysis">Kernel Fisher discriminant analysis</a></li>
<li><a href="/wiki/Logit" title="Logit">Logit</a> (for <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>)</li>
<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="/wiki/Multiple_discriminant_analysis" title="Multiple discriminant analysis">Multiple discriminant analysis</a></li>
<li><a href="/wiki/Multidimensional_scaling" title="Multidimensional scaling">Multidimensional scaling</a></li>
<li><a href="/wiki/Pattern_recognition" title="Pattern recognition">Pattern recognition</a></li>
<li><a href="/wiki/Preference_regression" title="Preference regression">Preference regression</a></li>
<li><a href="/wiki/Quadratic_classifier" title="Quadratic classifier">Quadratic classifier</a></li>
<li><a href="/wiki/Statistical_classification" title="Statistical classification">Statistical classification</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=22" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class="reflist">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-Fisher:1936-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-Fisher:1936_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Fisher:1936_1-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1133582631">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style><cite id="CITEREFFisher1936" class="citation journal cs1"><a href="/wiki/Ronald_Fisher" title="Ronald Fisher">Fisher, R. A.</a> (1936). <a rel="nofollow" class="external text" href="https://digital.library.adelaide.edu.au/dspace/bitstream/2440/15227/1/138.pdf">"The Use of Multiple Measurements in Taxonomic Problems"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/Annals_of_Eugenics" class="mw-redirect" title="Annals of Eugenics">Annals of Eugenics</a></i>. <b>7</b> (2): 179–188. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1111%2Fj.1469-1809.1936.tb02137.x">10.1111/j.1469-1809.1936.tb02137.x</a>. <a href="/wiki/Hdl_(identifier)" class="mw-redirect" title="Hdl (identifier)">hdl</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://hdl.handle.net/2440%2F15227">2440/15227</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Eugenics&amp;rft.atitle=The+Use+of+Multiple+Measurements+in+Taxonomic+Problems&amp;rft.volume=7&amp;rft.issue=2&amp;rft.pages=179-188&amp;rft.date=1936&amp;rft_id=info%3Ahdl%2F2440%2F15227&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1469-1809.1936.tb02137.x&amp;rft.aulast=Fisher&amp;rft.aufirst=R.+A.&amp;rft_id=https%3A%2F%2Fdigital.library.adelaide.edu.au%2Fdspace%2Fbitstream%2F2440%2F15227%2F1%2F138.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-McLachlan:2004-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-McLachlan:2004_2-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFMcLachlan2004" class="citation book cs1">McLachlan, G. J. (2004). <i>Discriminant Analysis and Statistical Pattern Recognition</i>. Wiley Interscience. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-471-69115-0" title="Special:BookSources/978-0-471-69115-0"><bdi>978-0-471-69115-0</bdi></a>. <a href="/wiki/MR_(identifier)" class="mw-redirect" title="MR (identifier)">MR</a>&#160;<a rel="nofollow" class="external text" href="https://mathscinet.ams.org/mathscinet-getitem?mr=1190469">1190469</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Discriminant+Analysis+and+Statistical+Pattern+Recognition&amp;rft.pub=Wiley+Interscience&amp;rft.date=2004&amp;rft.isbn=978-0-471-69115-0&amp;rft_id=https%3A%2F%2Fmathscinet.ams.org%2Fmathscinet-getitem%3Fmr%3D1190469%23id-name%3DMR&amp;rft.aulast=McLachlan&amp;rft.aufirst=G.+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Analyzing Quantitative Data: An Introduction for Social Researchers, Debra Wetcher-Hendricks, p.288</span>
</li>
<li id="cite_note-Martinez:2001-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-Martinez:2001_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Martinez:2001_4-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFMartinezKak2001" class="citation journal cs1">Martinez, A. M.; Kak, A. C. (2001). <a rel="nofollow" class="external text" href="http://www.ece.osu.edu/~aleix/pami01.pdf">"PCA versus LDA"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence" title="IEEE Transactions on Pattern Analysis and Machine Intelligence">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></i>. <b>23</b> (2): 228–233. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F34.908974">10.1109/34.908974</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=PCA+versus+LDA&amp;rft.volume=23&amp;rft.issue=2&amp;rft.pages=228-233&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1109%2F34.908974&amp;rft.aulast=Martinez&amp;rft.aufirst=A.+M.&amp;rft.au=Kak%2C+A.+C.&amp;rft_id=http%3A%2F%2Fwww.ece.osu.edu%2F~aleix%2Fpami01.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-Abdi_2007-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-Abdi_2007_5-0">^</a></b></span> <span class="reference-text">Abdi, H. (2007) <a rel="nofollow" class="external text" href="http://www.utdallas.edu/~herve/Abdi-DCA2007-pretty.pdf">"Discriminant correspondence analysis."</a> In: N.J. Salkind (Ed.): <i>Encyclopedia of Measurement and Statistic</i>. Thousand Oaks (CA): Sage. pp.&#160;270–275.</span>
</li>
<li id="cite_note-Perriere_2003-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-Perriere_2003_6-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFPerriereThioulouse2003" class="citation journal cs1">Perriere, G.; Thioulouse, J. (2003). "Use of Correspondence Discriminant Analysis to predict the subcellular location of bacterial proteins". <i>Computer Methods and Programs in Biomedicine</i>. <b>70</b> (2): 99–105. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0169-2607%2802%2900011-1">10.1016/s0169-2607(02)00011-1</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/12507786">12507786</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Methods+and+Programs+in+Biomedicine&amp;rft.atitle=Use+of+Correspondence+Discriminant+Analysis+to+predict+the+subcellular+location+of+bacterial+proteins&amp;rft.volume=70&amp;rft.issue=2&amp;rft.pages=99-105&amp;rft.date=2003&amp;rft_id=info%3Adoi%2F10.1016%2Fs0169-2607%2802%2900011-1&amp;rft_id=info%3Apmid%2F12507786&amp;rft.aulast=Perriere&amp;rft.aufirst=G.&amp;rft.au=Thioulouse%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-buy-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-buy_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-buy_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-buy_7-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-buy_7-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-buy_7-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-buy_7-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-buy_7-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-buy_7-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-buy_7-8"><sup><i><b>i</b></i></sup></a> <a href="#cite_ref-buy_7-9"><sup><i><b>j</b></i></sup></a></span> <span class="reference-text">Büyüköztürk, Ş. &amp; Çokluk-Bökeoğlu, Ö. (2008). <a rel="nofollow" class="external text" href="https://ejer.com.tr/wp-content/uploads/2021/01/ejer_2008_issue_33.pdf">Discriminant function analysis: Concept and application</a>. Egitim Arastirmalari - Eurasian Journal of Educational Research, 33, 73-92. </span>
</li>
<li id="cite_note-cohen-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-cohen_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-cohen_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Cohen et al. Applied Multiple Regression/Correlation Analysis for the Behavioural Sciences 3rd ed. (2003). Taylor &amp; Francis Group.</span>
</li>
<li id="cite_note-green-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-green_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-green_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-green_9-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-green_9-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-green_9-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-green_9-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-green_9-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-green_9-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-green_9-8"><sup><i><b>i</b></i></sup></a> <a href="#cite_ref-green_9-9"><sup><i><b>j</b></i></sup></a> <a href="#cite_ref-green_9-10"><sup><i><b>k</b></i></sup></a></span> <span class="reference-text">Green, S.B. Salkind, N. J. &amp; Akey, T. M. (2008). <a rel="nofollow" class="external text" href="https://www.tandfonline.com/doi/pdf/10.1198/tas.2005.s139">Using SPSS for Windows and Macintosh: Analyzing and understanding data</a>. New Jersey: Prentice Hall.</span>
</li>
<li id="cite_note-Venables:2002-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-Venables:2002_10-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFVenablesRipley2002" class="citation book cs1">Venables, W. N.; <a href="/wiki/Brian_Ripley" class="mw-redirect" title="Brian Ripley">Ripley, B. D.</a> (2002). <i>Modern Applied Statistics with S</i> (4th&#160;ed.). Springer Verlag. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-387-95457-8" title="Special:BookSources/978-0-387-95457-8"><bdi>978-0-387-95457-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Modern+Applied+Statistics+with+S&amp;rft.edition=4th&amp;rft.pub=Springer+Verlag&amp;rft.date=2002&amp;rft.isbn=978-0-387-95457-8&amp;rft.aulast=Venables&amp;rft.aufirst=W.+N.&amp;rft.au=Ripley%2C+B.+D.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">Lachenbruch, P. A. (1975). <i>Discriminant analysis</i>. NY: Hafner</span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text">Klecka, William R. (1980). <i>Discriminant analysis</i>. Quantitative Applications in the Social Sciences Series, No. 19. Thousand Oaks, CA: Sage Publications.</span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text">Hardle, W., Simar, L. (2007). <i>Applied Multivariate Statistical Analysis</i>. Springer Berlin Heidelberg. pp.&#160;289–303.</span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text">Garson, G. D. (2008). Discriminant function analysis. <a rel="nofollow" class="external free" href="https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm">https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm</a>.</span>
</li>
<li id="cite_note-har-15"><span class="mw-cite-backlink">^ <a href="#cite_ref-har_15-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-har_15-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-har_15-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">Hardle, W., Simar, L. (2007). <i><a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/e49a/3ed1560a0979f5ca0146c1aca7ef98e64af7.pdf">Applied Multivariate Statistical Analysis</a></i>. Springer Berlin Heidelberg. pp. 289-303.</span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFIsrael2006" class="citation journal cs1">Israel, Steven A. (June 2006). "Performance Metrics: How and When". <i>Geocarto International</i>. <b>21</b> (2): 23–32. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1080%2F10106040608542380">10.1080/10106040608542380</a>. <a href="/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/1010-6049">1010-6049</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:122376081">122376081</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Geocarto+International&amp;rft.atitle=Performance+Metrics%3A+How+and+When&amp;rft.volume=21&amp;rft.issue=2&amp;rft.pages=23-32&amp;rft.date=2006-06&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A122376081%23id-name%3DS2CID&amp;rft.issn=1010-6049&amp;rft_id=info%3Adoi%2F10.1080%2F10106040608542380&amp;rft.aulast=Israel&amp;rft.aufirst=Steven+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-garson-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-garson_17-0">^</a></b></span> <span class="reference-text">Garson, G. D. (2008). Discriminant function analysis. <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm">"PA 765: Discriminant Function Analysis"</a>. Archived from <a rel="nofollow" class="external text" href="http://www2.chass.ncsu.edu/garson/pa765/discrim.htm">the original</a> on 2008-03-12<span class="reference-accessdate">. Retrieved <span class="nowrap">2008-03-04</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=PA+765%3A+Discriminant+Function+Analysis&amp;rft_id=http%3A%2F%2Fwww2.chass.ncsu.edu%2Fgarson%2Fpa765%2Fdiscrim.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span> .</span>
</li>
<li id="cite_note-Rao:1948-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-Rao:1948_18-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFRao1948" class="citation journal cs1"><a href="/wiki/Calyampudi_Radhakrishna_Rao" class="mw-redirect" title="Calyampudi Radhakrishna Rao">Rao, R. C.</a> (1948). "The utilization of multiple measurements in problems of biological classification". <i>Journal of the Royal Statistical Society, Series B</i>. <b>10</b> (2): 159–203. <a href="/wiki/JSTOR_(identifier)" class="mw-redirect" title="JSTOR (identifier)">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="https://www.jstor.org/stable/2983775">2983775</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Royal+Statistical+Society%2C+Series+B&amp;rft.atitle=The+utilization+of+multiple+measurements+in+problems+of+biological+classification&amp;rft.volume=10&amp;rft.issue=2&amp;rft.pages=159-203&amp;rft.date=1948&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F2983775%23id-name%3DJSTOR&amp;rft.aulast=Rao&amp;rft.aufirst=R.+C.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-:0-19"><span class="mw-cite-backlink">^ <a href="#cite_ref-:0_19-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_19-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFAliyari_GhassabehRudziczMoghaddam2015" class="citation journal cs1">Aliyari Ghassabeh, Youness; Rudzicz, Frank; Moghaddam, Hamid Abrishami (2015-06-01). "Fast incremental LDA feature extraction". <i>Pattern Recognition</i>. <b>48</b> (6): 1999–2012. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2015PatRe..48.1999A">2015PatRe..48.1999A</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.patcog.2014.12.012">10.1016/j.patcog.2014.12.012</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recognition&amp;rft.atitle=Fast+incremental+LDA+feature+extraction&amp;rft.volume=48&amp;rft.issue=6&amp;rft.pages=1999-2012&amp;rft.date=2015-06-01&amp;rft_id=info%3Adoi%2F10.1016%2Fj.patcog.2014.12.012&amp;rft_id=info%3Abibcode%2F2015PatRe..48.1999A&amp;rft.aulast=Aliyari+Ghassabeh&amp;rft.aufirst=Youness&amp;rft.au=Rudzicz%2C+Frank&amp;rft.au=Moghaddam%2C+Hamid+Abrishami&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-:1-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-:1_20-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFChatterjeeRoychowdhury1997" class="citation journal cs1">Chatterjee, C.; Roychowdhury, V.P. (1997-05-01). "On self-organizing algorithms and networks for class-separability features". <i>IEEE Transactions on Neural Networks</i>. <b>8</b> (3): 663–678. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F72.572105">10.1109/72.572105</a>. <a href="/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/1045-9227">1045-9227</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/18255669">18255669</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks&amp;rft.atitle=On+self-organizing+algorithms+and+networks+for+class-separability+features&amp;rft.volume=8&amp;rft.issue=3&amp;rft.pages=663-678&amp;rft.date=1997-05-01&amp;rft.issn=1045-9227&amp;rft_id=info%3Apmid%2F18255669&amp;rft_id=info%3Adoi%2F10.1109%2F72.572105&amp;rft.aulast=Chatterjee&amp;rft.aufirst=C.&amp;rft.au=Roychowdhury%2C+V.P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFDemirOzmehmet2005" class="citation journal cs1">Demir, G. K.; Ozmehmet, K. (2005-03-01). "Online Local Learning Algorithms for Linear Discriminant Analysis". <i>Pattern Recognit. Lett</i>. <b>26</b> (4): 421–431. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2005PaReL..26..421D">2005PaReL..26..421D</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.patrec.2004.08.005">10.1016/j.patrec.2004.08.005</a>. <a href="/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/0167-8655">0167-8655</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recognit.+Lett.&amp;rft.atitle=Online+Local+Learning+Algorithms+for+Linear+Discriminant+Analysis&amp;rft.volume=26&amp;rft.issue=4&amp;rft.pages=421-431&amp;rft.date=2005-03-01&amp;rft.issn=0167-8655&amp;rft_id=info%3Adoi%2F10.1016%2Fj.patrec.2004.08.005&amp;rft_id=info%3Abibcode%2F2005PaReL..26..421D&amp;rft.aulast=Demir&amp;rft.aufirst=G.+K.&amp;rft.au=Ozmehmet%2C+K.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFYuYang2001" class="citation journal cs1">Yu, H.; Yang, J. (2001). "A direct LDA algorithm for high-dimensional data — with application to face recognition". <i>Pattern Recognition</i>. <b>34</b> (10): 2067–2069. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2001PatRe..34.2067Y">2001PatRe..34.2067Y</a>. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.3507">10.1.1.70.3507</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0031-3203%2800%2900162-x">10.1016/s0031-3203(00)00162-x</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recognition&amp;rft.atitle=A+direct+LDA+algorithm+for+high-dimensional+data+%E2%80%94+with+application+to+face+recognition&amp;rft.volume=34&amp;rft.issue=10&amp;rft.pages=2067-2069&amp;rft.date=2001&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.70.3507%23id-name%3DCiteSeerX&amp;rft_id=info%3Adoi%2F10.1016%2Fs0031-3203%2800%2900162-x&amp;rft_id=info%3Abibcode%2F2001PatRe..34.2067Y&amp;rft.aulast=Yu&amp;rft.aufirst=H.&amp;rft.au=Yang%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-Friedman:2001-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-Friedman:2001_23-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFFriedman1989" class="citation journal cs1">Friedman, J. H. (1989). <a rel="nofollow" class="external text" href="http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-pub-4389.pdf">"Regularized Discriminant Analysis"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/Journal_of_the_American_Statistical_Association" title="Journal of the American Statistical Association">Journal of the American Statistical Association</a></i>. <b>84</b> (405): 165–175. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.382.2682">10.1.1.382.2682</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2307%2F2289860">10.2307/2289860</a>. <a href="/wiki/JSTOR_(identifier)" class="mw-redirect" title="JSTOR (identifier)">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="https://www.jstor.org/stable/2289860">2289860</a>. <a href="/wiki/MR_(identifier)" class="mw-redirect" title="MR (identifier)">MR</a>&#160;<a rel="nofollow" class="external text" href="https://mathscinet.ams.org/mathscinet-getitem?mr=0999675">0999675</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Regularized+Discriminant+Analysis&amp;rft.volume=84&amp;rft.issue=405&amp;rft.pages=165-175&amp;rft.date=1989&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.382.2682%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fmathscinet.ams.org%2Fmathscinet-getitem%3Fmr%3D0999675%23id-name%3DMR&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F2289860%23id-name%3DJSTOR&amp;rft_id=info%3Adoi%2F10.2307%2F2289860&amp;rft.aulast=Friedman&amp;rft.aufirst=J.+H.&amp;rft_id=http%3A%2F%2Fwww.slac.stanford.edu%2Fcgi-wrap%2Fgetdoc%2Fslac-pub-4389.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFAhdesmäkiStrimmer2010" class="citation journal cs1">Ahdesmäki, M.; Strimmer, K. (2010). "Feature selection in omics prediction problems using cat scores and false nondiscovery rate control". <i>Annals of Applied Statistics</i>. <b>4</b> (1): 503–519. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/0903.2003">0903.2003</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1214%2F09-aoas277">10.1214/09-aoas277</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:2508935">2508935</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Applied+Statistics&amp;rft.atitle=Feature+selection+in+omics+prediction+problems+using+cat+scores+and+false+nondiscovery+rate+control&amp;rft.volume=4&amp;rft.issue=1&amp;rft.pages=503-519&amp;rft.date=2010&amp;rft_id=info%3Aarxiv%2F0903.2003&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A2508935%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1214%2F09-aoas277&amp;rft.aulast=Ahdesm%C3%A4ki&amp;rft.aufirst=M.&amp;rft.au=Strimmer%2C+K.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFAltman1968" class="citation journal cs1"><a href="/wiki/Edward_I._Altman" class="mw-redirect" title="Edward I. Altman">Altman, Edward I.</a> (1968). "Financial Ratios, Discriminant Analysis and the Prediction of Corporate Bankruptcy". <i><a href="/wiki/The_Journal_of_Finance" title="The Journal of Finance">The Journal of Finance</a></i>. <b>23</b> (4): 589–609. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2307%2F2978933">10.2307/2978933</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Journal+of+Finance&amp;rft.atitle=Financial+Ratios%2C+Discriminant+Analysis+and+the+Prediction+of+Corporate+Bankruptcy&amp;rft.volume=23&amp;rft.issue=4&amp;rft.pages=589-609&amp;rft.date=1968&amp;rft_id=info%3Adoi%2F10.2307%2F2978933&amp;rft.aulast=Altman&amp;rft.aufirst=Edward+I.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFAgarwalTaffler2005" class="citation web cs1">Agarwal, Vineet; Taffler, Richard (2005). <a rel="nofollow" class="external text" href="https://efmaefm.org/0efmameetings/EFMA%20ANNUAL%20MEETINGS/2006-Madrid/papers/932609_full.pdf">"Twenty-five years of z-scores in the UK: do they really work?"</a> <span class="cs1-format">(PDF)</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Twenty-five+years+of+z-scores+in+the+UK%3A+do+they+really+work%3F&amp;rft.date=2005&amp;rft.aulast=Agarwal&amp;rft.aufirst=Vineet&amp;rft.au=Taffler%2C+Richard&amp;rft_id=https%3A%2F%2Fefmaefm.org%2F0efmameetings%2FEFMA%2520ANNUAL%2520MEETINGS%2F2006-Madrid%2Fpapers%2F932609_full.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFAgarwalTaffler2007" class="citation journal cs1">Agarwal, Vineet; Taffler, Richard (2007). "Twenty-Five Years of the Taffler Z-Score Model: Does It Really Have Predictive Ability?". <i>Accounting and Business Research</i> (37): 285–300. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1080%2F00014788.2007.9663313">10.1080/00014788.2007.9663313</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Accounting+and+Business+Research&amp;rft.atitle=Twenty-Five+Years+of+the+Taffler+Z-Score+Model%3A+Does+It+Really+Have+Predictive+Ability%3F&amp;rft.issue=37&amp;rft.pages=285-300&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1080%2F00014788.2007.9663313&amp;rft.aulast=Agarwal&amp;rft.aufirst=Vineet&amp;rft.au=Taffler%2C+Richard&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFBimpongArhinNanDanso2020" class="citation journal cs1">Bimpong, Patrick; et&#160;al. (2020). <a rel="nofollow" class="external text" href="https://finance.expertjournals.com/23597712-801/">"Assessing Predictive Power and Earnings Manipulations. Applied Study on Listed Consumer Goods and Service Companies in Ghana Using 3 Z-Score Models"</a>. <i>Expert Journal of Finance</i>. <b>8</b> (1): 1–26.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Expert+Journal+of+Finance&amp;rft.atitle=Assessing+Predictive+Power+and+Earnings+Manipulations.+Applied+Study+on+Listed+Consumer+Goods+and+Service+Companies+in+Ghana+Using+3+Z-Score+Models&amp;rft.volume=8&amp;rft.issue=1&amp;rft.pages=1-26&amp;rft.date=2020&amp;rft.aulast=Bimpong&amp;rft.aufirst=Patrick&amp;rft.au=Arhin%2C+Ishmael&amp;rft.au=Nan%2C+Thomas+hezkeal+Khela&amp;rft.au=Danso%2C+Edward&amp;rft.au=Opoku%2C+Pious&amp;rft.au=Benedict%2C+Arthur&amp;rft.au=Tettey%2C+Grace&amp;rft_id=https%3A%2F%2Ffinance.expertjournals.com%2F23597712-801%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFPreisnerGuiomarMachadoMenezes2010" class="citation journal cs1">Preisner, O; Guiomar, R; Machado, J; Menezes, JC; Lopes, JA (2010). <a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2876429">"Application of Fourier transform infrared spectroscopy and chemometrics for differentiation of Salmonella enterica serovar Enteritidis phage types"</a>. <i>Appl Environ Microbiol</i>. <b>76</b> (11): 3538–3544. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2010ApEnM..76.3538P">2010ApEnM..76.3538P</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1128%2Faem.01589-09">10.1128/aem.01589-09</a>. <a href="/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2876429">2876429</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/20363777">20363777</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Appl+Environ+Microbiol&amp;rft.atitle=Application+of+Fourier+transform+infrared+spectroscopy+and+chemometrics+for+differentiation+of+Salmonella+enterica+serovar+Enteritidis+phage+types&amp;rft.volume=76&amp;rft.issue=11&amp;rft.pages=3538-3544&amp;rft.date=2010&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2876429%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F20363777&amp;rft_id=info%3Adoi%2F10.1128%2Faem.01589-09&amp;rft_id=info%3Abibcode%2F2010ApEnM..76.3538P&amp;rft.aulast=Preisner&amp;rft.aufirst=O&amp;rft.au=Guiomar%2C+R&amp;rft.au=Machado%2C+J&amp;rft.au=Menezes%2C+JC&amp;rft.au=Lopes%2C+JA&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2876429&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFDavidLynneHanFoley2010" class="citation journal cs1">David, DE; Lynne, AM; Han, J; Foley, SL (2010). <a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2976202">"Evaluation of virulence factor profiling in the characterization of veterinary Escherichia coli isolates"</a>. <i>Appl Environ Microbiol</i>. <b>76</b> (22): 7509–7513. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2010ApEnM..76.7509D">2010ApEnM..76.7509D</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1128%2Faem.00726-10">10.1128/aem.00726-10</a>. <a href="/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2976202">2976202</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/20889790">20889790</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Appl+Environ+Microbiol&amp;rft.atitle=Evaluation+of+virulence+factor+profiling+in+the+characterization+of+veterinary+Escherichia+coli+isolates&amp;rft.volume=76&amp;rft.issue=22&amp;rft.pages=7509-7513&amp;rft.date=2010&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2976202%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F20889790&amp;rft_id=info%3Adoi%2F10.1128%2Faem.00726-10&amp;rft_id=info%3Abibcode%2F2010ApEnM..76.7509D&amp;rft.aulast=David&amp;rft.aufirst=DE&amp;rft.au=Lynne%2C+AM&amp;rft.au=Han%2C+J&amp;rft.au=Foley%2C+SL&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2976202&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFTahmasebiHezarkhaniMortazavi2010" class="citation journal cs1">Tahmasebi, P.; Hezarkhani, A.; Mortazavi, M. (2010). <a rel="nofollow" class="external text" href="http://ajbasweb.com/old/ajbas/2010/564-576.pdf">"Application of discriminant analysis for alteration separation; sungun copper deposit, East Azerbaijan, Iran. Australian"</a> <span class="cs1-format">(PDF)</span>. <i>Journal of Basic and Applied Sciences</i>. <b>6</b> (4): 564–576.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Basic+and+Applied+Sciences&amp;rft.atitle=Application+of+discriminant+analysis+for+alteration+separation%3B+sungun+copper+deposit%2C+East+Azerbaijan%2C+Iran.+Australian&amp;rft.volume=6&amp;rft.issue=4&amp;rft.pages=564-576&amp;rft.date=2010&amp;rft.aulast=Tahmasebi&amp;rft.aufirst=P.&amp;rft.au=Hezarkhani%2C+A.&amp;rft.au=Mortazavi%2C+M.&amp;rft_id=http%3A%2F%2Fajbasweb.com%2Fold%2Fajbas%2F2010%2F564-576.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFTrevor_HastieRobert_TibshiraniJerome_Friedman" class="citation book cs1">Trevor Hastie; Robert Tibshirani; Jerome Friedman. <i>The Elements of Statistical Learning. Data Mining, Inference, and Prediction</i> (second&#160;ed.). Springer. p.&#160;128.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Elements+of+Statistical+Learning.+Data+Mining%2C+Inference%2C+and+Prediction&amp;rft.pages=128&amp;rft.edition=second&amp;rft.pub=Springer&amp;rft.au=Trevor+Hastie&amp;rft.au=Robert+Tibshirani&amp;rft.au=Jerome+Friedman&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text">Kainen P.C. (1997) <a rel="nofollow" class="external text" href="https://web.archive.org/web/20190226172352/http://pdfs.semanticscholar.org/708f/8e0a95ba5977072651c0681f3c7b8f09eca3.pdf">Utilizing geometric anomalies of high dimension: When complexity makes computation easier</a>. In: Kárný M., Warwick K. (eds) Computer Intensive Methods in Control and Signal Processing: The Curse of Dimensionality, Springer, 1997, pp. 282–294.</span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text">Donoho, D., Tanner, J. (2009) <a rel="nofollow" class="external text" href="https://arxiv.org/abs/0906.2530">Observed universality of phase transitions in high-dimensional geometry, with implications for modern data analysis and signal processing</a>, Phil. Trans. R. Soc. A 367, 4273–4293.</span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFGorbanGolubkovGrechuckMirkes2018" class="citation journal cs1">Gorban, Alexander N.; Golubkov, Alexander; Grechuck, Bogdan; Mirkes, Evgeny M.; Tyukin, Ivan Y. (2018). "Correction of AI systems by linear discriminants: Probabilistic foundations". <i>Information Sciences</i>. <b>466</b>: 303–322. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1811.05321">1811.05321</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.ins.2018.07.040">10.1016/j.ins.2018.07.040</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:52876539">52876539</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Information+Sciences&amp;rft.atitle=Correction+of+AI+systems+by+linear+discriminants%3A+Probabilistic+foundations&amp;rft.volume=466&amp;rft.pages=303-322&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1811.05321&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A52876539%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1016%2Fj.ins.2018.07.040&amp;rft.aulast=Gorban&amp;rft.aufirst=Alexander+N.&amp;rft.au=Golubkov%2C+Alexander&amp;rft.au=Grechuck%2C+Bogdan&amp;rft.au=Mirkes%2C+Evgeny+M.&amp;rft.au=Tyukin%2C+Ivan+Y.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text">Guédon, O., Milman, E. (2011) <a rel="nofollow" class="external text" href="https://arxiv.org/abs/1011.0943">Interpolating thin-shell and sharp large-deviation estimates for isotropic log-concave measures</a>, Geom. Funct. Anal. 21 (5), 1043–1068.</span>
</li>
<li id="cite_note-GMT2019-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-GMT2019_37-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFGorbanMakarovTyukin2019" class="citation journal cs1">Gorban, Alexander N.; Makarov, Valeri A.; Tyukin, Ivan Y. (July 2019). <a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.plrev.2018.09.005">"The unreasonable effectiveness of small neural ensembles in high-dimensional brain"</a>. <i>Physics of Life Reviews</i>. <b>29</b>: 55–88. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1809.07656">1809.07656</a></span>. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2019PhLRv..29...55G">2019PhLRv..29...55G</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.plrev.2018.09.005">10.1016/j.plrev.2018.09.005</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/30366739">30366739</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Physics+of+Life+Reviews&amp;rft.atitle=The+unreasonable+effectiveness+of+small+neural+ensembles+in+high-dimensional+brain&amp;rft.volume=29&amp;rft.pages=55-88&amp;rft.date=2019-07&amp;rft_id=info%3Aarxiv%2F1809.07656&amp;rft_id=info%3Apmid%2F30366739&amp;rft_id=info%3Adoi%2F10.1016%2Fj.plrev.2018.09.005&amp;rft_id=info%3Abibcode%2F2019PhLRv..29...55G&amp;rft.aulast=Gorban&amp;rft.aufirst=Alexander+N.&amp;rft.au=Makarov%2C+Valeri+A.&amp;rft.au=Tyukin%2C+Ivan+Y.&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252Fj.plrev.2018.09.005&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=23" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFDudaHartStork2000" class="citation book cs1">Duda, R. O.; Hart, P. E.; Stork, D. H. (2000). <i>Pattern Classification</i> (2nd&#160;ed.). Wiley Interscience. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-471-05669-0" title="Special:BookSources/978-0-471-05669-0"><bdi>978-0-471-05669-0</bdi></a>. <a href="/wiki/MR_(identifier)" class="mw-redirect" title="MR (identifier)">MR</a>&#160;<a rel="nofollow" class="external text" href="https://mathscinet.ams.org/mathscinet-getitem?mr=1802993">1802993</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Pattern+Classification&amp;rft.edition=2nd&amp;rft.pub=Wiley+Interscience&amp;rft.date=2000&amp;rft.isbn=978-0-471-05669-0&amp;rft_id=https%3A%2F%2Fmathscinet.ams.org%2Fmathscinet-getitem%3Fmr%3D1802993%23id-name%3DMR&amp;rft.aulast=Duda&amp;rft.aufirst=R.+O.&amp;rft.au=Hart%2C+P.+E.&amp;rft.au=Stork%2C+D.+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFHilbe2009" class="citation book cs1">Hilbe, J. M. (2009). <i>Logistic Regression Models</i>. Chapman &amp; Hall/CRC Press. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4200-7575-5" title="Special:BookSources/978-1-4200-7575-5"><bdi>978-1-4200-7575-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Logistic+Regression+Models&amp;rft.pub=Chapman+%26+Hall%2FCRC+Press&amp;rft.date=2009&amp;rft.isbn=978-1-4200-7575-5&amp;rft.aulast=Hilbe&amp;rft.aufirst=J.+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFMika,_S.1999" class="citation book cs1">Mika, S.; et&#160;al. (1999). "Fisher discriminant analysis with kernels". <i>Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468)</i>. pp.&#160;41–48. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.9904">10.1.1.35.9904</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FNNSP.1999.788121">10.1109/NNSP.1999.788121</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-7803-5673-3" title="Special:BookSources/978-0-7803-5673-3"><bdi>978-0-7803-5673-3</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:8473401">8473401</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Fisher+discriminant+analysis+with+kernels&amp;rft.btitle=Neural+Networks+for+Signal+Processing+IX%3A+Proceedings+of+the+1999+IEEE+Signal+Processing+Society+Workshop+%28Cat.+No.98TH8468%29&amp;rft.pages=41-48&amp;rft.date=1999&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.35.9904%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A8473401%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FNNSP.1999.788121&amp;rft.isbn=978-0-7803-5673-3&amp;rft.au=Mika%2C+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><span class="cs1-maint citation-comment"><code class="cs1-code">{{<a href="/wiki/Template:Cite_book" title="Template:Cite book">cite book</a>}}</code>:  CS1 maint: date and year (<a href="/wiki/Category:CS1_maint:_date_and_year" title="Category:CS1 maint: date and year">link</a>)</span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFMcFarlandDonald2001" class="citation journal cs1">McFarland, H. Richard; Donald, St. P. Richards (2001). <a rel="nofollow" class="external text" href="https://doi.org/10.1006%2Fjmva.2000.1924">"Exact Misclassification Probabilities for Plug-In Normal Quadratic Discriminant Functions. I. The Equal-Means Case"</a>. <i>Journal of Multivariate Analysis</i>. <b>77</b> (1): 21–53. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1006%2Fjmva.2000.1924">10.1006/jmva.2000.1924</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Multivariate+Analysis&amp;rft.atitle=Exact+Misclassification+Probabilities+for+Plug-In+Normal+Quadratic+Discriminant+Functions.+I.+The+Equal-Means+Case&amp;rft.volume=77&amp;rft.issue=1&amp;rft.pages=21-53&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1006%2Fjmva.2000.1924&amp;rft.aulast=McFarland&amp;rft.aufirst=H.+Richard&amp;rft.au=Donald%2C+St.+P.+Richards&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1006%252Fjmva.2000.1924&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFMcFarlandDonald2002" class="citation journal cs1">McFarland, H. Richard; Donald, St. P. Richards (2002). <a rel="nofollow" class="external text" href="https://doi.org/10.1006%2Fjmva.2001.2034">"Exact Misclassification Probabilities for Plug-In Normal Quadratic Discriminant Functions. II. The Heterogeneous Case"</a>. <i>Journal of Multivariate Analysis</i>. <b>82</b> (2): 299–330. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1006%2Fjmva.2001.2034">10.1006/jmva.2001.2034</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Multivariate+Analysis&amp;rft.atitle=Exact+Misclassification+Probabilities+for+Plug-In+Normal+Quadratic+Discriminant+Functions.+II.+The+Heterogeneous+Case&amp;rft.volume=82&amp;rft.issue=2&amp;rft.pages=299-330&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1006%2Fjmva.2001.2034&amp;rft.aulast=McFarland&amp;rft.aufirst=H.+Richard&amp;rft.au=Donald%2C+St.+P.+Richards&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1006%252Fjmva.2001.2034&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFHaghighatAbdel-MottalebAlhalabi2016" class="citation journal cs1">Haghighat, M.; Abdel-Mottaleb, M.; Alhalabi, W. (2016). <a rel="nofollow" class="external text" href="https://zenodo.org/record/889881">"Discriminant Correlation Analysis: Real-Time Feature Level Fusion for Multimodal Biometric Recognition"</a>. <i>IEEE Transactions on Information Forensics and Security</i>. <b>11</b> (9): 1984–1996. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FTIFS.2016.2569061">10.1109/TIFS.2016.2569061</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:15624506">15624506</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Information+Forensics+and+Security&amp;rft.atitle=Discriminant+Correlation+Analysis%3A+Real-Time+Feature+Level+Fusion+for+Multimodal+Biometric+Recognition&amp;rft.volume=11&amp;rft.issue=9&amp;rft.pages=1984-1996&amp;rft.date=2016&amp;rft_id=info%3Adoi%2F10.1109%2FTIFS.2016.2569061&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A15624506%23id-name%3DS2CID&amp;rft.aulast=Haghighat&amp;rft.aufirst=M.&amp;rft.au=Abdel-Mottaleb%2C+M.&amp;rft.au=Alhalabi%2C+W.&amp;rft_id=https%3A%2F%2Fzenodo.org%2Frecord%2F889881&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span></li></ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=24" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1134653256">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9;display:flow-root}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style><div class="side-box side-box-right plainlinks sistersitebox"><style data-mw-deduplicate="TemplateStyles:r1126788409">.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}</style>
<div class="side-box-flex">
<div class="side-box-image"><span class="noviewer" typeof="mw:File"><span><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Wikiversity_logo_2017.svg/40px-Wikiversity_logo_2017.svg.png" decoding="async" width="40" height="33" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Wikiversity_logo_2017.svg/60px-Wikiversity_logo_2017.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Wikiversity_logo_2017.svg/80px-Wikiversity_logo_2017.svg.png 2x" data-file-width="626" data-file-height="512" /></span></span></div>
<div class="side-box-text plainlist">Wikiversity has learning resources about <i><b><a href="https://en.wikiversity.org/wiki/Discriminant_function_analysis" class="extiw" title="v:Discriminant function analysis">Discriminant function analysis</a></b></i></div></div>
</div>
<ul><li><a rel="nofollow" class="external text" href="https://github.com/mhaghighat/dcaFuse">Discriminant Correlation Analysis (DCA) of the Haghighat article (see above)</a></li>
<li><a rel="nofollow" class="external text" href="http://www.alglib.net/dataanalysis/lineardiscriminantanalysis.php">ALGLIB</a> contains open-source LDA implementation in C# / C++ / Pascal / VBA.</li>
<li><a rel="nofollow" class="external text" href="https://www.mltut.com/linear-discriminant-analysis-python-complete-and-easy-guide/">LDA in Python</a>- LDA implementation in Python</li>
<li><a rel="nofollow" class="external text" href="http://people.revoledu.com/kardi/tutorial/LDA/index.html">LDA tutorial using MS Excel</a></li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20150405124836/http://biostat.katerynakon.in.ua/en/prognosis/discriminant-analysis.html">Biomedical statistics. Discriminant analysis</a></li>
<li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=azXCzI57Yfc"><span class="plainlinks">StatQuest: Linear Discriminant Analysis (LDA) clearly explained</span></a> on <a href="/wiki/YouTube_video_(identifier)" class="mw-redirect" title="YouTube video (identifier)">YouTube</a></li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm">Course notes, Discriminant function analysis by G. David Garson, NC State University</a></li>
<li><a rel="nofollow" class="external text" href="http://people.revoledu.com/kardi/tutorial/LDA/">Discriminant analysis tutorial in Microsoft Excel by Kardi Teknomo</a></li>
<li><a rel="nofollow" class="external text" href="http://www.psychstat.missouristate.edu/multibook/mlt03m.html">Course notes, Discriminant function analysis by David W. Stockburger, Missouri State University</a></li>
<li><a rel="nofollow" class="external text" href="http://userwww.sfsu.edu/~efc/classes/biol710/discrim/discrim.pdf">Discriminant function analysis (DA) by John Poulsen and Aaron French, San Francisco State University</a></li></ul>
<div class="navbox-styles"><style data-mw-deduplicate="TemplateStyles:r1129693374">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:" · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}</style><style data-mw-deduplicate="TemplateStyles:r1061467846">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}</style></div><div role="navigation" class="navbox" aria-labelledby="Statistics" style="padding:3px"><table class="nowraplinks hlist mw-collapsible uncollapsed navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><style data-mw-deduplicate="TemplateStyles:r1063604349">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}</style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="/wiki/Template:Statistics" title="Template:Statistics"><abbr title="View this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Statistics" title="Template talk:Statistics"><abbr title="Discuss this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">t</abbr></a></li><li class="nv-edit"><a href="/wiki/Special:EditPage/Template:Statistics" title="Special:EditPage/Template:Statistics"><abbr title="Edit this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">e</abbr></a></li></ul></div><div id="Statistics" style="font-size:114%;margin:0 4em"><a href="/wiki/Statistics" title="Statistics">Statistics</a></div></th></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><a href="/wiki/Outline_of_statistics" title="Outline of statistics">Outline</a></li>
<li><a href="/wiki/List_of_statistics_articles" title="List of statistics articles">Index</a></li></ul>
</div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Descriptive_statistics" style="font-size:114%;margin:0 4em"><a href="/wiki/Descriptive_statistics" title="Descriptive statistics">Descriptive statistics</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Continuous_probability_distribution" class="mw-redirect" title="Continuous probability distribution">Continuous data</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Central_tendency" title="Central tendency">Center</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Mean" title="Mean">Mean</a>
<ul><li><a href="/wiki/Arithmetic_mean" title="Arithmetic mean">Arithmetic</a></li>
<li><a href="/wiki/Arithmetic%E2%80%93geometric_mean" title="Arithmetic–geometric mean">Arithmetic-Geometric</a></li>
<li><a href="/wiki/Cubic_mean" title="Cubic mean">Cubic</a></li>
<li><a href="/wiki/Generalized_mean" title="Generalized mean">Generalized/power</a></li>
<li><a href="/wiki/Geometric_mean" title="Geometric mean">Geometric</a></li>
<li><a href="/wiki/Harmonic_mean" title="Harmonic mean">Harmonic</a></li>
<li><a href="/wiki/Heronian_mean" title="Heronian mean">Heronian</a></li>
<li><a href="/wiki/Heinz_mean" title="Heinz mean">Heinz</a></li>
<li><a href="/wiki/Lehmer_mean" title="Lehmer mean">Lehmer</a></li></ul></li>
<li><a href="/wiki/Median" title="Median">Median</a></li>
<li><a href="/wiki/Mode_(statistics)" title="Mode (statistics)">Mode</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Statistical_dispersion" title="Statistical dispersion">Dispersion</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Average_absolute_deviation" title="Average absolute deviation">Average absolute deviation</a></li>
<li><a href="/wiki/Coefficient_of_variation" title="Coefficient of variation">Coefficient of variation</a></li>
<li><a href="/wiki/Interquartile_range" title="Interquartile range">Interquartile range</a></li>
<li><a href="/wiki/Percentile" title="Percentile">Percentile</a></li>
<li><a href="/wiki/Range_(statistics)" title="Range (statistics)">Range</a></li>
<li><a href="/wiki/Standard_deviation" title="Standard deviation">Standard deviation</a></li>
<li><a href="/wiki/Variance#Sample_variance" title="Variance">Variance</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Shape_of_the_distribution" class="mw-redirect" title="Shape of the distribution">Shape</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Central_limit_theorem" title="Central limit theorem">Central limit theorem</a></li>
<li><a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">Moments</a>
<ul><li><a href="/wiki/Kurtosis" title="Kurtosis">Kurtosis</a></li>
<li><a href="/wiki/L-moment" title="L-moment">L-moments</a></li>
<li><a href="/wiki/Skewness" title="Skewness">Skewness</a></li></ul></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Count_data" title="Count data">Count data</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Index_of_dispersion" title="Index of dispersion">Index of dispersion</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Summary tables</th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Contingency_table" title="Contingency table">Contingency table</a></li>
<li><a href="/wiki/Frequency_distribution" class="mw-redirect" title="Frequency distribution">Frequency distribution</a></li>
<li><a href="/wiki/Grouped_data" title="Grouped data">Grouped data</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Correlation_and_dependence" class="mw-redirect" title="Correlation and dependence">Dependence</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Partial_correlation" title="Partial correlation">Partial correlation</a></li>
<li><a href="/wiki/Pearson_correlation_coefficient" title="Pearson correlation coefficient">Pearson product-moment correlation</a></li>
<li><a href="/wiki/Rank_correlation" title="Rank correlation">Rank correlation</a>
<ul><li><a href="/wiki/Kendall_rank_correlation_coefficient" title="Kendall rank correlation coefficient">Kendall's τ</a></li>
<li><a href="/wiki/Spearman%27s_rank_correlation_coefficient" title="Spearman&#39;s rank correlation coefficient">Spearman's ρ</a></li></ul></li>
<li><a href="/wiki/Scatter_plot" title="Scatter plot">Scatter plot</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Statistical_graphics" title="Statistical graphics">Graphics</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Bar_chart" title="Bar chart">Bar chart</a></li>
<li><a href="/wiki/Biplot" title="Biplot">Biplot</a></li>
<li><a href="/wiki/Box_plot" title="Box plot">Box plot</a></li>
<li><a href="/wiki/Control_chart" title="Control chart">Control chart</a></li>
<li><a href="/wiki/Correlogram" title="Correlogram">Correlogram</a></li>
<li><a href="/wiki/Fan_chart_(statistics)" title="Fan chart (statistics)">Fan chart</a></li>
<li><a href="/wiki/Forest_plot" title="Forest plot">Forest plot</a></li>
<li><a href="/wiki/Histogram" title="Histogram">Histogram</a></li>
<li><a href="/wiki/Pie_chart" title="Pie chart">Pie chart</a></li>
<li><a href="/wiki/Q%E2%80%93Q_plot" title="Q–Q plot">Q–Q plot</a></li>
<li><a href="/wiki/Radar_chart" title="Radar chart">Radar chart</a></li>
<li><a href="/wiki/Run_chart" title="Run chart">Run chart</a></li>
<li><a href="/wiki/Scatter_plot" title="Scatter plot">Scatter plot</a></li>
<li><a href="/wiki/Stem-and-leaf_display" title="Stem-and-leaf display">Stem-and-leaf display</a></li>
<li><a href="/wiki/Violin_plot" title="Violin plot">Violin plot</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Data_collection" style="font-size:114%;margin:0 4em"><a href="/wiki/Data_collection" title="Data collection">Data collection</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Design_of_experiments" title="Design of experiments">Study design</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Effect_size" title="Effect size">Effect size</a></li>
<li><a href="/wiki/Missing_data" title="Missing data">Missing data</a></li>
<li><a href="/wiki/Optimal_design" title="Optimal design">Optimal design</a></li>
<li><a href="/wiki/Statistical_population" title="Statistical population">Population</a></li>
<li><a href="/wiki/Replication_(statistics)" title="Replication (statistics)">Replication</a></li>
<li><a href="/wiki/Sample_size_determination" title="Sample size determination">Sample size determination</a></li>
<li><a href="/wiki/Statistic" title="Statistic">Statistic</a></li>
<li><a href="/wiki/Statistical_power" class="mw-redirect" title="Statistical power">Statistical power</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Survey_methodology" title="Survey methodology">Survey methodology</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">Sampling</a>
<ul><li><a href="/wiki/Cluster_sampling" title="Cluster sampling">Cluster</a></li>
<li><a href="/wiki/Stratified_sampling" title="Stratified sampling">Stratified</a></li></ul></li>
<li><a href="/wiki/Opinion_poll" title="Opinion poll">Opinion poll</a></li>
<li><a href="/wiki/Questionnaire" title="Questionnaire">Questionnaire</a></li>
<li><a href="/wiki/Standard_error" title="Standard error">Standard error</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Experiment" title="Experiment">Controlled experiments</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Blocking_(statistics)" title="Blocking (statistics)">Blocking</a></li>
<li><a href="/wiki/Factorial_experiment" title="Factorial experiment">Factorial experiment</a></li>
<li><a href="/wiki/Interaction_(statistics)" title="Interaction (statistics)">Interaction</a></li>
<li><a href="/wiki/Random_assignment" title="Random assignment">Random assignment</a></li>
<li><a href="/wiki/Randomized_controlled_trial" title="Randomized controlled trial">Randomized controlled trial</a></li>
<li><a href="/wiki/Randomized_experiment" title="Randomized experiment">Randomized experiment</a></li>
<li><a href="/wiki/Scientific_control" title="Scientific control">Scientific control</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Adaptive designs</th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Adaptive_clinical_trial" class="mw-redirect" title="Adaptive clinical trial">Adaptive clinical trial</a></li>
<li><a href="/wiki/Stochastic_approximation" title="Stochastic approximation">Stochastic approximation</a></li>
<li><a href="/wiki/Up-and-Down_Designs" title="Up-and-Down Designs">Up-and-down designs</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Observational_study" title="Observational study">Observational studies</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Cohort_study" title="Cohort study">Cohort study</a></li>
<li><a href="/wiki/Cross-sectional_study" title="Cross-sectional study">Cross-sectional study</a></li>
<li><a href="/wiki/Natural_experiment" title="Natural experiment">Natural experiment</a></li>
<li><a href="/wiki/Quasi-experiment" title="Quasi-experiment">Quasi-experiment</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Statistical_inference" style="font-size:114%;margin:0 4em"><a href="/wiki/Statistical_inference" title="Statistical inference">Statistical inference</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Statistical_theory" title="Statistical theory">Statistical theory</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Population_(statistics)" class="mw-redirect" title="Population (statistics)">Population</a></li>
<li><a href="/wiki/Statistic" title="Statistic">Statistic</a></li>
<li><a href="/wiki/Probability_distribution" title="Probability distribution">Probability distribution</a></li>
<li><a href="/wiki/Sampling_distribution" title="Sampling distribution">Sampling distribution</a>
<ul><li><a href="/wiki/Order_statistic" title="Order statistic">Order statistic</a></li></ul></li>
<li><a href="/wiki/Empirical_distribution_function" title="Empirical distribution function">Empirical distribution</a>
<ul><li><a href="/wiki/Density_estimation" title="Density estimation">Density estimation</a></li></ul></li>
<li><a href="/wiki/Statistical_model" title="Statistical model">Statistical model</a>
<ul><li><a href="/wiki/Model_specification" class="mw-redirect" title="Model specification">Model specification</a></li>
<li><a href="/wiki/Lp_space" title="Lp space">L<sup><i>p</i></sup> space</a></li></ul></li>
<li><a href="/wiki/Statistical_parameter" title="Statistical parameter">Parameter</a>
<ul><li><a href="/wiki/Location_parameter" title="Location parameter">location</a></li>
<li><a href="/wiki/Scale_parameter" title="Scale parameter">scale</a></li>
<li><a href="/wiki/Shape_parameter" title="Shape parameter">shape</a></li></ul></li>
<li><a href="/wiki/Parametric_statistics" title="Parametric statistics">Parametric family</a>
<ul><li><a href="/wiki/Likelihood_function" title="Likelihood function">Likelihood</a>&#160;<a href="/wiki/Monotone_likelihood_ratio" title="Monotone likelihood ratio"><span style="font-size:85%;">(monotone)</span></a></li>
<li><a href="/wiki/Location%E2%80%93scale_family" title="Location–scale family">Location–scale family</a></li>
<li><a href="/wiki/Exponential_family" title="Exponential family">Exponential family</a></li></ul></li>
<li><a href="/wiki/Completeness_(statistics)" title="Completeness (statistics)">Completeness</a></li>
<li><a href="/wiki/Sufficient_statistic" title="Sufficient statistic">Sufficiency</a></li>
<li><a href="/wiki/Plug-in_principle" class="mw-redirect" title="Plug-in principle">Statistical functional</a>
<ul><li><a href="/wiki/Bootstrapping_(statistics)" title="Bootstrapping (statistics)">Bootstrap</a></li>
<li><a href="/wiki/U-statistic" title="U-statistic">U</a></li>
<li><a href="/wiki/V-statistic" title="V-statistic">V</a></li></ul></li>
<li><a href="/wiki/Optimal_decision" title="Optimal decision">Optimal decision</a>
<ul><li><a href="/wiki/Loss_function" title="Loss function">loss function</a></li></ul></li>
<li><a href="/wiki/Efficiency_(statistics)" title="Efficiency (statistics)">Efficiency</a></li>
<li><a href="/wiki/Statistical_distance" title="Statistical distance">Statistical distance</a>
<ul><li><a href="/wiki/Divergence_(statistics)" title="Divergence (statistics)">divergence</a></li></ul></li>
<li><a href="/wiki/Asymptotic_theory_(statistics)" title="Asymptotic theory (statistics)">Asymptotics</a></li>
<li><a href="/wiki/Robust_statistics" title="Robust statistics">Robustness</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Frequentist_inference" title="Frequentist inference">Frequentist inference</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Point_estimation" title="Point estimation">Point estimation</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Estimating_equations" title="Estimating equations">Estimating equations</a>
<ul><li><a href="/wiki/Maximum_likelihood" class="mw-redirect" title="Maximum likelihood">Maximum likelihood</a></li>
<li><a href="/wiki/Method_of_moments_(statistics)" title="Method of moments (statistics)">Method of moments</a></li>
<li><a href="/wiki/M-estimator" title="M-estimator">M-estimator</a></li>
<li><a href="/wiki/Minimum_distance_estimation" class="mw-redirect" title="Minimum distance estimation">Minimum distance</a></li></ul></li>
<li><a href="/wiki/Bias_of_an_estimator" title="Bias of an estimator">Unbiased estimators</a>
<ul><li><a href="/wiki/Minimum-variance_unbiased_estimator" title="Minimum-variance unbiased estimator">Mean-unbiased minimum-variance</a>
<ul><li><a href="/wiki/Rao%E2%80%93Blackwell_theorem" title="Rao–Blackwell theorem">Rao–Blackwellization</a></li>
<li><a href="/wiki/Lehmann%E2%80%93Scheff%C3%A9_theorem" title="Lehmann–Scheffé theorem">Lehmann–Scheffé theorem</a></li></ul></li>
<li><a href="/wiki/Median-unbiased_estimator" class="mw-redirect" title="Median-unbiased estimator">Median unbiased</a></li></ul></li>
<li><a href="/wiki/Plug-in_principle" class="mw-redirect" title="Plug-in principle">Plug-in</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Interval_estimation" title="Interval estimation">Interval estimation</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Confidence_interval" title="Confidence interval">Confidence interval</a></li>
<li><a href="/wiki/Pivotal_quantity" title="Pivotal quantity">Pivot</a></li>
<li><a href="/wiki/Likelihood_interval" class="mw-redirect" title="Likelihood interval">Likelihood interval</a></li>
<li><a href="/wiki/Prediction_interval" title="Prediction interval">Prediction interval</a></li>
<li><a href="/wiki/Tolerance_interval" title="Tolerance interval">Tolerance interval</a></li>
<li><a href="/wiki/Resampling_(statistics)" title="Resampling (statistics)">Resampling</a>
<ul><li><a href="/wiki/Bootstrapping_(statistics)" title="Bootstrapping (statistics)">Bootstrap</a></li>
<li><a href="/wiki/Jackknife_resampling" title="Jackknife resampling">Jackknife</a></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Statistical_hypothesis_testing" title="Statistical hypothesis testing">Testing hypotheses</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/One-_and_two-tailed_tests" title="One- and two-tailed tests">1- &amp; 2-tails</a></li>
<li><a href="/wiki/Power_(statistics)" class="mw-redirect" title="Power (statistics)">Power</a>
<ul><li><a href="/wiki/Uniformly_most_powerful_test" title="Uniformly most powerful test">Uniformly most powerful test</a></li></ul></li>
<li><a href="/wiki/Permutation_test" title="Permutation test">Permutation test</a>
<ul><li><a href="/wiki/Randomization_test" class="mw-redirect" title="Randomization test">Randomization test</a></li></ul></li>
<li><a href="/wiki/Multiple_comparisons" class="mw-redirect" title="Multiple comparisons">Multiple comparisons</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Parametric_statistics" title="Parametric statistics">Parametric tests</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Likelihood-ratio_test" title="Likelihood-ratio test">Likelihood-ratio</a></li>
<li><a href="/wiki/Score_test" title="Score test">Score/Lagrange multiplier</a></li>
<li><a href="/wiki/Wald_test" title="Wald test">Wald</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Specific tests</th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><td colspan="2" class="navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Z-test" title="Z-test"><i>Z</i>-test <span style="font-size:85%;">(normal)</span></a></li>
<li><a href="/wiki/Student%27s_t-test" title="Student&#39;s t-test">Student's <i>t</i>-test</a></li>
<li><a href="/wiki/F-test" title="F-test"><i>F</i>-test</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Goodness_of_fit" title="Goodness of fit">Goodness of fit</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Chi-squared_test" title="Chi-squared test">Chi-squared</a></li>
<li><a href="/wiki/G-test" title="G-test"><i>G</i>-test</a></li>
<li><a href="/wiki/Kolmogorov%E2%80%93Smirnov_test" title="Kolmogorov–Smirnov test">Kolmogorov–Smirnov</a></li>
<li><a href="/wiki/Anderson%E2%80%93Darling_test" title="Anderson–Darling test">Anderson–Darling</a></li>
<li><a href="/wiki/Lilliefors_test" title="Lilliefors test">Lilliefors</a></li>
<li><a href="/wiki/Jarque%E2%80%93Bera_test" title="Jarque–Bera test">Jarque–Bera</a></li>
<li><a href="/wiki/Shapiro%E2%80%93Wilk_test" title="Shapiro–Wilk test">Normality <span style="font-size:85%;">(Shapiro–Wilk)</span></a></li>
<li><a href="/wiki/Likelihood-ratio_test" title="Likelihood-ratio test">Likelihood-ratio test</a></li>
<li><a href="/wiki/Model_selection" title="Model selection">Model selection</a>
<ul><li><a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">Cross validation</a></li>
<li><a href="/wiki/Akaike_information_criterion" title="Akaike information criterion">AIC</a></li>
<li><a href="/wiki/Bayesian_information_criterion" title="Bayesian information criterion">BIC</a></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Rank_statistics" class="mw-redirect" title="Rank statistics">Rank statistics</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Sign_test" title="Sign test">Sign</a>
<ul><li><a href="/wiki/Sample_median" class="mw-redirect" title="Sample median">Sample median</a></li></ul></li>
<li><a href="/wiki/Wilcoxon_signed-rank_test" title="Wilcoxon signed-rank test">Signed rank <span style="font-size:85%;">(Wilcoxon)</span></a>
<ul><li><a href="/wiki/Hodges%E2%80%93Lehmann_estimator" title="Hodges–Lehmann estimator">Hodges–Lehmann estimator</a></li></ul></li>
<li><a href="/wiki/Mann%E2%80%93Whitney_U_test" title="Mann–Whitney U test">Rank sum <span style="font-size:85%;">(Mann–Whitney)</span></a></li>
<li><a href="/wiki/Nonparametric_statistics" title="Nonparametric statistics">Nonparametric</a> <a href="/wiki/Analysis_of_variance" title="Analysis of variance">anova</a>
<ul><li><a href="/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance" title="Kruskal–Wallis one-way analysis of variance">1-way <span style="font-size:85%;">(Kruskal–Wallis)</span></a></li>
<li><a href="/wiki/Friedman_test" title="Friedman test">2-way <span style="font-size:85%;">(Friedman)</span></a></li>
<li><a href="/wiki/Jonckheere%27s_trend_test" title="Jonckheere&#39;s trend test">Ordered alternative <span style="font-size:85%;">(Jonckheere–Terpstra)</span></a></li></ul></li>
<li><a href="/wiki/Van_der_Waerden_test" title="Van der Waerden test">Van der Waerden test</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Bayesian_inference" title="Bayesian inference">Bayesian inference</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Bayesian_probability" title="Bayesian probability">Bayesian probability</a>
<ul><li><a href="/wiki/Prior_probability" title="Prior probability">prior</a></li>
<li><a href="/wiki/Posterior_probability" title="Posterior probability">posterior</a></li></ul></li>
<li><a href="/wiki/Credible_interval" title="Credible interval">Credible interval</a></li>
<li><a href="/wiki/Bayes_factor" title="Bayes factor">Bayes factor</a></li>
<li><a href="/wiki/Bayes_estimator" title="Bayes estimator">Bayesian estimator</a>
<ul><li><a href="/wiki/Maximum_a_posteriori_estimation" title="Maximum a posteriori estimation">Maximum posterior estimator</a></li></ul></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="CorrelationRegression_analysis" style="font-size:114%;margin:0 4em"><div class="hlist"><ul><li><a href="/wiki/Correlation_and_dependence" class="mw-redirect" title="Correlation and dependence">Correlation</a></li><li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></li></ul></div></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Correlation_and_dependence" class="mw-redirect" title="Correlation and dependence">Correlation</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Pearson_product-moment_correlation_coefficient" class="mw-redirect" title="Pearson product-moment correlation coefficient">Pearson product-moment</a></li>
<li><a href="/wiki/Partial_correlation" title="Partial correlation">Partial correlation</a></li>
<li><a href="/wiki/Confounding" title="Confounding">Confounding variable</a></li>
<li><a href="/wiki/Coefficient_of_determination" title="Coefficient of determination">Coefficient of determination</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Errors_and_residuals" title="Errors and residuals">Errors and residuals</a></li>
<li><a href="/wiki/Regression_validation" title="Regression validation">Regression validation</a></li>
<li><a href="/wiki/Mixed_model" title="Mixed model">Mixed effects models</a></li>
<li><a href="/wiki/Simultaneous_equations_model" title="Simultaneous equations model">Simultaneous equations models</a></li>
<li><a href="/wiki/Multivariate_adaptive_regression_splines" class="mw-redirect" title="Multivariate adaptive regression splines">Multivariate adaptive regression splines (MARS)</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Simple_linear_regression" title="Simple linear regression">Simple linear regression</a></li>
<li><a href="/wiki/Ordinary_least_squares" title="Ordinary least squares">Ordinary least squares</a></li>
<li><a href="/wiki/General_linear_model" title="General linear model">General linear model</a></li>
<li><a href="/wiki/Bayesian_linear_regression" title="Bayesian linear regression">Bayesian regression</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Non-standard predictors</th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Nonlinear_regression" title="Nonlinear regression">Nonlinear regression</a></li>
<li><a href="/wiki/Nonparametric_regression" title="Nonparametric regression">Nonparametric</a></li>
<li><a href="/wiki/Semiparametric_regression" title="Semiparametric regression">Semiparametric</a></li>
<li><a href="/wiki/Isotonic_regression" title="Isotonic regression">Isotonic</a></li>
<li><a href="/wiki/Robust_regression" title="Robust regression">Robust</a></li>
<li><a href="/wiki/Heteroscedasticity" class="mw-redirect" title="Heteroscedasticity">Heteroscedasticity</a></li>
<li><a href="/wiki/Homoscedasticity" class="mw-redirect" title="Homoscedasticity">Homoscedasticity</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Generalized_linear_model" title="Generalized linear model">Generalized linear model</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Exponential_family" title="Exponential family">Exponential families</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic <span style="font-size:85%;">(Bernoulli)</span></a>&#160;/&#32;<a href="/wiki/Binomial_regression" title="Binomial regression">Binomial</a>&#160;/&#32;<a href="/wiki/Poisson_regression" title="Poisson regression">Poisson regressions</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Partition_of_sums_of_squares" title="Partition of sums of squares">Partition of variance</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Analysis_of_variance" title="Analysis of variance">Analysis of variance (ANOVA, anova)</a></li>
<li><a href="/wiki/Analysis_of_covariance" title="Analysis of covariance">Analysis of covariance</a></li>
<li><a href="/wiki/Multivariate_analysis_of_variance" title="Multivariate analysis of variance">Multivariate ANOVA</a></li>
<li><a href="/wiki/Degrees_of_freedom_(statistics)" title="Degrees of freedom (statistics)">Degrees of freedom</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks mw-collapsible uncollapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Categorical_/_Multivariate_/_Time-series_/_Survival_analysis" style="font-size:114%;margin:0 4em"><a href="/wiki/Categorical_variable" title="Categorical variable">Categorical</a>&#160;/&#32;<a href="/wiki/Multivariate_statistics" title="Multivariate statistics">Multivariate</a>&#160;/&#32;<a href="/wiki/Time_series" title="Time series">Time-series</a>&#160;/&#32;<a href="/wiki/Survival_analysis" title="Survival analysis">Survival analysis</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Categorical_variable" title="Categorical variable">Categorical</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Cohen%27s_kappa" title="Cohen&#39;s kappa">Cohen's kappa</a></li>
<li><a href="/wiki/Contingency_table" title="Contingency table">Contingency table</a></li>
<li><a href="/wiki/Graphical_model" title="Graphical model">Graphical model</a></li>
<li><a href="/wiki/Poisson_regression" title="Poisson regression">Log-linear model</a></li>
<li><a href="/wiki/McNemar%27s_test" title="McNemar&#39;s test">McNemar's test</a></li>
<li><a href="/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics" title="Cochran–Mantel–Haenszel statistics">Cochran–Mantel–Haenszel statistics</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Multivariate_statistics" title="Multivariate statistics">Multivariate</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/General_linear_model" title="General linear model">Regression</a></li>
<li><a href="/wiki/Multivariate_analysis_of_variance" title="Multivariate analysis of variance">Manova</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">Principal components</a></li>
<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">Canonical correlation</a></li>
<li><a class="mw-selflink selflink">Discriminant analysis</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Cluster analysis</a></li>
<li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Structural_equation_modeling" title="Structural equation modeling">Structural equation model</a>
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li></ul></li>
<li><a href="/wiki/Multivariate_distribution" class="mw-redirect" title="Multivariate distribution">Multivariate distributions</a>
<ul><li><a href="/wiki/Elliptical_distribution" title="Elliptical distribution">Elliptical distributions</a>
<ul><li><a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">Normal</a></li></ul></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Time_series" title="Time series">Time-series</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;">General</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Decomposition_of_time_series" title="Decomposition of time series">Decomposition</a></li>
<li><a href="/wiki/Trend_estimation" class="mw-redirect" title="Trend estimation">Trend</a></li>
<li><a href="/wiki/Stationary_process" title="Stationary process">Stationarity</a></li>
<li><a href="/wiki/Seasonal_adjustment" title="Seasonal adjustment">Seasonal adjustment</a></li>
<li><a href="/wiki/Exponential_smoothing" title="Exponential smoothing">Exponential smoothing</a></li>
<li><a href="/wiki/Cointegration" title="Cointegration">Cointegration</a></li>
<li><a href="/wiki/Structural_break" title="Structural break">Structural break</a></li>
<li><a href="/wiki/Granger_causality" title="Granger causality">Granger causality</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;">Specific tests</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Dickey%E2%80%93Fuller_test" title="Dickey–Fuller test">Dickey–Fuller</a></li>
<li><a href="/wiki/Johansen_test" title="Johansen test">Johansen</a></li>
<li><a href="/wiki/Ljung%E2%80%93Box_test" title="Ljung–Box test">Q-statistic <span style="font-size:85%;">(Ljung–Box)</span></a></li>
<li><a href="/wiki/Durbin%E2%80%93Watson_statistic" title="Durbin–Watson statistic">Durbin–Watson</a></li>
<li><a href="/wiki/Breusch%E2%80%93Godfrey_test" title="Breusch–Godfrey test">Breusch–Godfrey</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Time_domain" title="Time domain">Time domain</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Autocorrelation" title="Autocorrelation">Autocorrelation (ACF)</a>
<ul><li><a href="/wiki/Partial_autocorrelation_function" title="Partial autocorrelation function">partial (PACF)</a></li></ul></li>
<li><a href="/wiki/Cross-correlation" title="Cross-correlation">Cross-correlation (XCF)</a></li>
<li><a href="/wiki/Autoregressive%E2%80%93moving-average_model" title="Autoregressive–moving-average model">ARMA model</a></li>
<li><a href="/wiki/Box%E2%80%93Jenkins_method" title="Box–Jenkins method">ARIMA model <span style="font-size:85%;">(Box–Jenkins)</span></a></li>
<li><a href="/wiki/Autoregressive_conditional_heteroskedasticity" title="Autoregressive conditional heteroskedasticity">Autoregressive conditional heteroskedasticity (ARCH)</a></li>
<li><a href="/wiki/Vector_autoregression" title="Vector autoregression">Vector autoregression (VAR)</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Frequency_domain" title="Frequency domain">Frequency domain</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Spectral_density_estimation" title="Spectral density estimation">Spectral density estimation</a></li>
<li><a href="/wiki/Fourier_analysis" title="Fourier analysis">Fourier analysis</a></li>
<li><a href="/wiki/Least-squares_spectral_analysis" title="Least-squares spectral analysis">Least-squares spectral analysis</a></li>
<li><a href="/wiki/Wavelet" title="Wavelet">Wavelet</a></li>
<li><a href="/wiki/Whittle_likelihood" title="Whittle likelihood">Whittle likelihood</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Survival_analysis" title="Survival analysis">Survival</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Survival_function" title="Survival function">Survival function</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Kaplan%E2%80%93Meier_estimator" title="Kaplan–Meier estimator">Kaplan–Meier estimator (product limit)</a></li>
<li><a href="/wiki/Proportional_hazards_model" title="Proportional hazards model">Proportional hazards models</a></li>
<li><a href="/wiki/Accelerated_failure_time_model" title="Accelerated failure time model">Accelerated failure time (AFT) model</a></li>
<li><a href="/wiki/First-hitting-time_model" title="First-hitting-time model">First hitting time</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Failure_rate" title="Failure rate">Hazard function</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Nelson%E2%80%93Aalen_estimator" title="Nelson–Aalen estimator">Nelson–Aalen estimator</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;">Test</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Log-rank_test" class="mw-redirect" title="Log-rank test">Log-rank test</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Applications" style="font-size:114%;margin:0 4em"><a href="/wiki/List_of_fields_of_application_of_statistics" title="List of fields of application of statistics">Applications</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Biostatistics" title="Biostatistics">Biostatistics</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Bioinformatics" title="Bioinformatics">Bioinformatics</a></li>
<li><a href="/wiki/Clinical_trial" title="Clinical trial">Clinical trials</a>&#160;/&#32;<a href="/wiki/Clinical_study_design" title="Clinical study design">studies</a></li>
<li><a href="/wiki/Epidemiology" title="Epidemiology">Epidemiology</a></li>
<li><a href="/wiki/Medical_statistics" title="Medical statistics">Medical statistics</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Engineering_statistics" title="Engineering statistics">Engineering statistics</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Chemometrics" title="Chemometrics">Chemometrics</a></li>
<li><a href="/wiki/Methods_engineering" title="Methods engineering">Methods engineering</a></li>
<li><a href="/wiki/Probabilistic_design" title="Probabilistic design">Probabilistic design</a></li>
<li><a href="/wiki/Statistical_process_control" title="Statistical process control">Process</a>&#160;/&#32;<a href="/wiki/Quality_control" title="Quality control">quality control</a></li>
<li><a href="/wiki/Reliability_engineering" title="Reliability engineering">Reliability</a></li>
<li><a href="/wiki/System_identification" title="System identification">System identification</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Social_statistics" title="Social statistics">Social statistics</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Actuarial_science" title="Actuarial science">Actuarial science</a></li>
<li><a href="/wiki/Census" title="Census">Census</a></li>
<li><a href="/wiki/Crime_statistics" title="Crime statistics">Crime statistics</a></li>
<li><a href="/wiki/Demographic_statistics" title="Demographic statistics">Demography</a></li>
<li><a href="/wiki/Econometrics" title="Econometrics">Econometrics</a></li>
<li><a href="/wiki/Jurimetrics" title="Jurimetrics">Jurimetrics</a></li>
<li><a href="/wiki/National_accounts" title="National accounts">National accounts</a></li>
<li><a href="/wiki/Official_statistics" title="Official statistics">Official statistics</a></li>
<li><a href="/wiki/Population_statistics" class="mw-redirect" title="Population statistics">Population statistics</a></li>
<li><a href="/wiki/Psychometrics" title="Psychometrics">Psychometrics</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Spatial_analysis" title="Spatial analysis">Spatial statistics</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Cartography" title="Cartography">Cartography</a></li>
<li><a href="/wiki/Environmental_statistics" title="Environmental statistics">Environmental statistics</a></li>
<li><a href="/wiki/Geographic_information_system" title="Geographic information system">Geographic information system</a></li>
<li><a href="/wiki/Geostatistics" title="Geostatistics">Geostatistics</a></li>
<li><a href="/wiki/Kriging" title="Kriging">Kriging</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><span class="noviewer" typeof="mw:File"><span title="Category"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png" decoding="async" width="16" height="16" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x" data-file-width="180" data-file-height="185" /></span></span><b><a href="/wiki/Category:Statistics" title="Category:Statistics">Category</a></b></li>
<li><b><span class="noviewer" typeof="mw:File"><a href="/wiki/File:Nuvola_apps_edu_mathematics_blue-p.svg" class="mw-file-description"><img alt="icon" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/28px-Nuvola_apps_edu_mathematics_blue-p.svg.png" decoding="async" width="28" height="28" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/42px-Nuvola_apps_edu_mathematics_blue-p.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png 2x" data-file-width="128" data-file-height="128" /></a></span>&#160;<a href="/wiki/Portal:Mathematics" title="Portal:Mathematics">Mathematics&#32;portal</a></b></li>
<li><span class="noviewer" typeof="mw:File"><span title="Commons page"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" decoding="async" width="12" height="16" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376" /></span></span><b><a href="https://commons.wikimedia.org/wiki/Category:Statistics" class="extiw" title="commons:Category:Statistics">Commons</a></b></li>
<li><span class="noviewer" typeof="mw:File"><span title="WikiProject"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/16px-People_icon.svg.png" decoding="async" width="16" height="16" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/24px-People_icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/32px-People_icon.svg.png 2x" data-file-width="100" data-file-height="100" /></span></span> <b><a href="/wiki/Wikipedia:WikiProject_Statistics" title="Wikipedia:WikiProject Statistics">WikiProject</a></b></li></ul>
</div></td></tr></tbody></table></div>
<div class="navbox-styles"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1061467846"></div><div role="navigation" class="navbox authority-control" aria-label="Navbox" style="padding:3px"><table class="nowraplinks hlist navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Help:Authority_control" title="Help:Authority control">Authority control databases</a>: National <span class="mw-valign-text-top noprint" typeof="mw:File/Frameless"><a href="https://www.wikidata.org/wiki/Q1228929#identifiers" title="Edit this at Wikidata"><img alt="Edit this at Wikidata" src="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png" decoding="async" width="10" height="10" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/15px-OOjs_UI_icon_edit-ltr-progressive.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png 2x" data-file-width="20" data-file-height="20" /></a></span></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><span class="uid"><a rel="nofollow" class="external text" href="http://uli.nli.org.il/F/?func=find-b&amp;local_base=NLX10&amp;find_code=UID&amp;request=987007555292305171">Israel</a></span></li>
<li><span class="uid"><a rel="nofollow" class="external text" href="https://id.loc.gov/authorities/sh85038374">United States</a></span></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw1454
Cached time: 20231010224459
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.676 seconds
Real time usage: 0.912 seconds
Preprocessor visited node count: 4427/1000000
Post‐expand include size: 229348/2097152 bytes
Template argument size: 4605/2097152 bytes
Highest expansion depth: 18/100
Expensive parser function count: 7/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 112353/5000000 bytes
Lua time usage: 0.363/10.000 seconds
Lua memory usage: 8017479/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  602.053      1 -total
 35.45%  213.451      1 Template:Reflist
 28.12%  169.311     22 Template:Cite_journal
 20.86%  125.583      1 Template:Statistics
 20.44%  123.063      1 Template:Navbox_with_collapsible_groups
 10.59%   63.773      6 Template:Clarify
  9.39%   56.507      6 Template:Fix-span
  8.30%   49.985      1 Template:Short_description
  6.39%   38.485     11 Template:Navbox
  5.22%   31.455     12 Template:Category_handler
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1470657-0!canonical and timestamp 20231010224458 and revision id 1170909811. Rendering was triggered because: page-view
 -->
</div><!--esi <esi:include src="/esitest-fa8a495983347898/content" /> --><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Linear_discriminant_analysis&amp;oldid=1170909811">https://en.wikipedia.org/w/index.php?title=Linear_discriminant_analysis&amp;oldid=1170909811</a>"</div></div>
					<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Classification_algorithms" title="Category:Classification algorithms">Classification algorithms</a></li><li><a href="/wiki/Category:Market_research" title="Category:Market research">Market research</a></li><li><a href="/wiki/Category:Market_segmentation" title="Category:Market segmentation">Market segmentation</a></li><li><a href="/wiki/Category:Statistical_classification" title="Category:Statistical classification">Statistical classification</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2019" title="Category:Wikipedia articles needing clarification from April 2019">Wikipedia articles needing clarification from April 2019</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2012" title="Category:Wikipedia articles needing clarification from April 2012">Wikipedia articles needing clarification from April 2012</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_May_2021" title="Category:Wikipedia articles needing clarification from May 2021">Wikipedia articles needing clarification from May 2021</a></li><li><a href="/wiki/Category:CS1_maint:_date_and_year" title="Category:CS1 maint: date and year">CS1 maint: date and year</a></li><li><a href="/wiki/Category:Articles_with_J9U_identifiers" title="Category:Articles with J9U identifiers">Articles with J9U identifiers</a></li><li><a href="/wiki/Category:Articles_with_LCCN_identifiers" title="Category:Articles with LCCN identifiers">Articles with LCCN identifiers</a></li></ul></div></div>
				</div>
			</main>
			
		</div>
		<div class="mw-footer-container">
			
<footer id="footer" class="mw-footer" role="contentinfo" >
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 17 August 2023, at 23:02<span class="anonymous-show">&#160;(UTC)</span>.</li>
	<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License">Creative Commons Attribution-ShareAlike License 4.0</a><a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="/wiki/Wikipedia:About">About Wikipedia</a></li>
	<li id="footer-places-disclaimers"><a href="/wiki/Wikipedia:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
	<li id="footer-places-wm-codeofconduct"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Universal_Code_of_Conduct">Code of Conduct</a></li>
	<li id="footer-places-developers"><a href="https://developer.wikimedia.org">Developers</a></li>
	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement">Cookie statement</a></li>
	<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Linear_discriminant_analysis&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy" /></a></li>
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/footer/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"></a></li>
</ul>

</footer>

		</div>
	</div> 
</div> 
<div class="vector-settings" id="p-dock-bottom">
	<ul>
		<li>
		
		<button class="cdx-button cdx-button--icon-only vector-limited-width-toggle" id=""><span class="vector-icon mw-ui-icon-fullScreen mw-ui-icon-wikimedia-fullScreen"></span>

<span>Toggle limited content width</span>
</button>
</li>
	</ul>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgHostname":"mw1454","wgBackendResponseTime":1059,"wgPageParseReport":{"limitreport":{"cputime":"0.676","walltime":"0.912","ppvisitednodes":{"value":4427,"limit":1000000},"postexpandincludesize":{"value":229348,"limit":2097152},"templateargumentsize":{"value":4605,"limit":2097152},"expansiondepth":{"value":18,"limit":100},"expensivefunctioncount":{"value":7,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":112353,"limit":5000000},"entityaccesscount":{"value":1,"limit":400},"timingprofile":["100.00%  602.053      1 -total"," 35.45%  213.451      1 Template:Reflist"," 28.12%  169.311     22 Template:Cite_journal"," 20.86%  125.583      1 Template:Statistics"," 20.44%  123.063      1 Template:Navbox_with_collapsible_groups"," 10.59%   63.773      6 Template:Clarify","  9.39%   56.507      6 Template:Fix-span","  8.30%   49.985      1 Template:Short_description","  6.39%   38.485     11 Template:Navbox","  5.22%   31.455     12 Template:Category_handler"]},"scribunto":{"limitreport-timeusage":{"value":"0.363","limit":"10.000"},"limitreport-memusage":{"value":8017479,"limit":52428800},"limitreport-logs":"table#1 {\n}\n"},"cachereport":{"origin":"mw1454","timestamp":"20231010224459","ttl":1814400,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Linear discriminant analysis","url":"https:\/\/en.wikipedia.org\/wiki\/Linear_discriminant_analysis","sameAs":"http:\/\/www.wikidata.org\/entity\/Q1228929","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q1228929","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2005-02-05T22:31:51Z","dateModified":"2023-08-17T23:02:43Z","headline":"method used in statistics, pattern recognition and machine learning"}</script>
</body>
</html>